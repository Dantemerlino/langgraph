{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI0xLxmm7HBa"
      },
      "source": [
        "# Get all Resident surgeries and case log data\n",
        "\n",
        "This code does the following: \n",
        "\n",
        "1) updates the [resident file](https://storage.cloud.google.com/shared-aif-bucket-3444/resident_cases/resident_data.json) if there are new ENT residents,\n",
        "\n",
        "2) Uploads the resident file,\n",
        "\n",
        "3) Uploads the [consultant file](https://storage.cloud.google.com/shared-aif-bucket-3444/resident_cases/ENT_consultants.xlsx),\n",
        "\n",
        "4) Uploads the [CPT code conversion file](https://storage.cloud.google.com/shared-aif-bucket-3444/resident_cases/cpt_database.xlsx),\n",
        "\n",
        "5) Launches a jupyter widget allowing the user select the residents and the date of interest,\n",
        "\n",
        "6) Performs a SQL query based on the user's selection extracting all cases for that resident over the defined period of time, using billing CPT codes to determine what CPT codes were performed during the case,\n",
        "\n",
        "7) Converts the billing CPT codes into codes appropriate for logging cases, based on the CPT code conversion file,\n",
        "\n",
        "8) Predicts special equipment used (robot, KTP, CO2 laser, sialendoscopy) based on the description of the case,\n",
        "\n",
        "9) Creates an excel spreadsheet with the modified CPT codes and all of the relevant details, so that it can be pasted into the ACGME caselog template.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Things that will require updating over time:\n",
        "\n",
        "1) When consultants are added to the ACGME website dropdown list, they need to be added to the [consultant file](https://storage.cloud.google.com/shared-aif-bucket-3444/resident_cases/ENT_consultants.xlsx) located in google cloud storage\n",
        "\n",
        "2) If errors are found or modifications are needed to adjust the CPT conversion file, it should be edited [here](https://storage.cloud.google.com/shared-aif-bucket-3444/resident_cases/cpt_database.xlsx) located in google cloud storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using the existing virtual environment...\n",
            "\n",
            "Installing packages...\n",
            "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (24.3.1)\n",
            "Collecting pip\n",
            "  Using cached pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Using cached pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.3.1\n",
            "    Uninstalling pip-24.3.1:\n",
            "      Successfully uninstalled pip-24.3.1\n",
            "Successfully installed pip-25.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting requests\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests)\n",
            "  Downloading charset_normalizer-3.4.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp312-cp312-macosx_10_13_universal2.whl (199 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [requests]\n",
            "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.4.26 charset-normalizer-3.4.2 idna-3.10 requests-2.32.3 urllib3-2.4.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Testing installation:\n",
            "Success! Requests from: /Users/dantemacstudio/Desktop/Claude_playground/MayoSQL/.venv/lib/python3.12/site-packages/requests/__init__.py\n",
            "Collecting google-cloud-storage>=2.10.0 (from -r requirements.txt (line 2))\n",
            "  Using cached google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting google-cloud-bigquery>=3.11.0 (from -r requirements.txt (line 3))\n",
            "  Downloading google_cloud_bigquery-3.33.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting google-auth>=2.22.0 (from -r requirements.txt (line 4))\n",
            "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib>=1.0.0 (from -r requirements.txt (line 5))\n",
            "  Using cached google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-auth-httplib2>=0.1.0 (from -r requirements.txt (line 6))\n",
            "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-cloud-pubsub>=2.18.0 (from -r requirements.txt (line 9))\n",
            "  Using cached google_cloud_pubsub-2.29.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting google-cloud-firestore>=2.11.0 (from -r requirements.txt (line 10))\n",
            "  Using cached google_cloud_firestore-2.20.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting google-cloud-compute>=1.11.0 (from -r requirements.txt (line 11))\n",
            "  Using cached google_cloud_compute-1.30.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting google-cloud-logging>=3.5.0 (from -r requirements.txt (line 12))\n",
            "  Using cached google_cloud_logging-3.12.1-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pandas>=2.0.0 (from -r requirements.txt (line 15))\n",
            "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
            "Collecting numpy<2 (from -r requirements.txt (line 16))\n",
            "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
            "Collecting db-dtypes>=1.0.0 (from -r requirements.txt (line 17))\n",
            "  Using cached db_dtypes-1.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tqdm>=4.65.0 (from -r requirements.txt (line 20))\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting jupyter>=1.0.0 (from -r requirements.txt (line 23))\n",
            "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting notebook>=7.0.0 (from -r requirements.txt (line 24))\n",
            "  Downloading notebook-7.4.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ipykernel>=6.25.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (6.29.5)\n",
            "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=2.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (2.4.0)\n",
            "Collecting python-dotenv>=1.0.0 (from -r requirements.txt (line 32))\n",
            "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting xlsxwriter (from -r requirements.txt (line 34))\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-api-core<3.0.0dev,>=2.15.0 (from google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Using cached google_api_core-2.25.0rc1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-cloud-core<3.0dev,>=2.4.2 (from google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Using cached google_crc32c-1.7.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (2.3 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.22.0->-r requirements.txt (line 4))\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.22.0->-r requirements.txt (line 4))\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=2.22.0->-r requirements.txt (line 4))\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->-r requirements.txt (line 28)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->-r requirements.txt (line 28)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.31.0->-r requirements.txt (line 28)) (2025.4.26)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Downloading protobuf-6.31.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=2.22.0->-r requirements.txt (line 4))\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: packaging>=24.2.0 in ./.venv/lib/python3.12/site-packages (from google-cloud-bigquery>=3.11.0->-r requirements.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./.venv/lib/python3.12/site-packages (from google-cloud-bigquery>=3.11.0->-r requirements.txt (line 3)) (2.9.0.post0)\n",
            "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery>=3.11.0->-r requirements.txt (line 3))\n",
            "  Using cached grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
            "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery>=3.11.0->-r requirements.txt (line 3))\n",
            "  Using cached grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=2.10.0->-r requirements.txt (line 2))\n",
            "  Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery>=3.11.0->-r requirements.txt (line 3)) (1.17.0)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib>=1.0.0->-r requirements.txt (line 5))\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting httplib2>=0.19.0 (from google-auth-httplib2>=0.1.0->-r requirements.txt (line 6))\n",
            "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting grpc-google-iam-v1<1.0.0,>=0.12.4 (from google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting opentelemetry-api>=1.27.0 (from google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-sdk>=1.27.0 (from google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting google-cloud-appengine-logging<2.0.0,>=0.1.3 (from google-cloud-logging>=3.5.0->-r requirements.txt (line 12))\n",
            "  Using cached google_cloud_appengine_logging-1.6.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting google-cloud-audit-log<1.0.0,>=0.3.1 (from google-cloud-logging>=3.5.0->-r requirements.txt (line 12))\n",
            "  Using cached google_cloud_audit_log-0.3.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=2.0.0->-r requirements.txt (line 15))\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=2.0.0->-r requirements.txt (line 15))\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyarrow>=13.0.0 (from db-dtypes>=1.0.0->-r requirements.txt (line 17))\n",
            "  Downloading pyarrow-20.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
            "Collecting jupyter-console (from jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting nbconvert (from jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting ipywidgets (from jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting jupyterlab (from jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading jupyterlab-4.4.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting notebook-shim<0.3,>=0.2 (from notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: tornado>=6.2.0 in ./.venv/lib/python3.12/site-packages (from notebook>=7.0.0->-r requirements.txt (line 24)) (6.5.1)\n",
            "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jinja2>=3.0.3 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: jupyter-client>=7.4.4 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24)) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24)) (5.7.2)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading prometheus_client-0.22.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24)) (26.4.0)\n",
            "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: traitlets>=5.6.0 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24)) (5.14.3)\n",
            "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting httpx>=0.25.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting setuptools>=41.1.0 (from jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: appnope in ./.venv/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.1.4)\n",
            "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 25)) (1.8.14)\n",
            "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 25)) (9.2.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 25)) (1.6.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ipykernel>=6.25.0->-r requirements.txt (line 25)) (7.0.0)\n",
            "Collecting sniffio>=1.1 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting typing_extensions>=4.5 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (6.7 kB)\n",
            "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2>=0.19.0->google-auth-httplib2>=0.1.0->-r requirements.txt (line 6))\n",
            "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (5.2.1)\n",
            "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (1.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.19.2)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (3.0.51)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (2.19.1)\n",
            "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.6.3)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.8.4)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading rpds_py-0.25.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24)) (4.3.8)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pyyaml>=5.3 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting beautifulsoup4 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting defusedxml (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting jupyterlab-pygments (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting nbclient>=0.5.0 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.27.0->google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.27.0->google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub>=2.18.0->-r requirements.txt (line 9))\n",
            "  Using cached opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.7.0)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=1.0.0->-r requirements.txt (line 5))\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
            "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 23))\n",
            "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=7.0.0->-r requirements.txt (line 24))\n",
            "  Downloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel>=6.25.0->-r requirements.txt (line 25)) (0.2.3)\n",
            "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
            "Using cached google_cloud_storage-3.1.0-py2.py3-none-any.whl (174 kB)\n",
            "Downloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached google_api_core-2.25.0rc1-py3-none-any.whl (160 kB)\n",
            "Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
            "Using cached google_crc32c-1.7.1-cp312-cp312-macosx_12_0_arm64.whl (30 kB)\n",
            "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading google_cloud_bigquery-3.33.0-py3-none-any.whl (253 kB)\n",
            "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
            "Using cached grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl (11.3 MB)\n",
            "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
            "Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
            "Using cached google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
            "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Using cached google_cloud_pubsub-2.29.0-py2.py3-none-any.whl (317 kB)\n",
            "Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\n",
            "Using cached google_cloud_firestore-2.20.2-py3-none-any.whl (358 kB)\n",
            "Using cached google_cloud_compute-1.30.0-py3-none-any.whl (3.3 MB)\n",
            "Using cached google_cloud_logging-3.12.1-py2.py3-none-any.whl (229 kB)\n",
            "Using cached google_cloud_appengine_logging-1.6.1-py3-none-any.whl (16 kB)\n",
            "Using cached google_cloud_audit_log-0.3.2-py3-none-any.whl (32 kB)\n",
            "Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
            "Using cached db_dtypes-1.4.3-py3-none-any.whl (18 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading notebook-7.4.2-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
            "Downloading jupyterlab-4.4.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
            "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
            "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
            "Downloading mistune-3.1.3-py3-none-any.whl (53 kB)\n",
            "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
            "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
            "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
            "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
            "Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
            "Using cached opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Using cached wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
            "Using cached opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading prometheus_client-0.22.0-py3-none-any.whl (62 kB)\n",
            "Downloading pyarrow-20.0.0-cp312-cp312-macosx_12_0_arm64.whl (30.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rpds_py-0.25.1-cp312-cp312-macosx_11_0_arm64.whl (350 kB)\n",
            "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
            "Downloading setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
            "Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
            "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
            "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
            "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
            "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Downloading types_python_dateutil-2.9.0.20250516-py3-none-any.whl (14 kB)\n",
            "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: webencodings, pytz, fastjsonschema, zipp, xlsxwriter, wrapt, widgetsnbextension, websocket-client, webcolors, uri-template, tzdata, typing_extensions, types-python-dateutil, tqdm, tinycss2, terminado, soupsieve, sniffio, setuptools, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pyyaml, python-json-logger, python-dotenv, pyparsing, pycparser, pyasn1, pyarrow, protobuf, prometheus-client, pandocfilters, overrides, oauthlib, numpy, mistune, MarkupSafe, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, h11, grpcio, google-crc32c, fqdn, defusedxml, cachetools, bleach, babel, attrs, async-lru, rsa, requests-oauthlib, referencing, pyasn1-modules, proto-plus, pandas, jupyter-server-terminals, jinja2, importlib-metadata, httplib2, httpcore, googleapis-common-protos, google-resumable-media, deprecated, cffi, beautifulsoup4, arrow, anyio, opentelemetry-api, jsonschema-specifications, isoduration, ipywidgets, httpx, grpcio-status, google-cloud-audit-log, google-auth, db-dtypes, argon2-cffi-bindings, opentelemetry-semantic-conventions, jupyter-console, jsonschema, grpc-google-iam-v1, google-auth-oauthlib, google-auth-httplib2, google-api-core, argon2-cffi, opentelemetry-sdk, nbformat, google-cloud-core, nbclient, jupyter-events, google-cloud-storage, google-cloud-pubsub, google-cloud-firestore, google-cloud-compute, google-cloud-bigquery, google-cloud-appengine-logging, nbconvert, google-cloud-logging, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108/108\u001b[0m [jupyter][notebook]jupyterlab]ver]gging]]]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 anyio-4.9.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.5 attrs-25.3.0 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 cachetools-5.5.2 cffi-1.17.1 db-dtypes-1.4.3 defusedxml-0.7.1 deprecated-1.2.18 fastjsonschema-2.21.1 fqdn-1.5.1 google-api-core-2.25.0rc1 google-auth-2.40.2 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.2.2 google-cloud-appengine-logging-1.6.1 google-cloud-audit-log-0.3.2 google-cloud-bigquery-3.33.0 google-cloud-compute-1.30.0 google-cloud-core-2.4.3 google-cloud-firestore-2.20.2 google-cloud-logging-3.12.1 google-cloud-pubsub-2.29.0 google-cloud-storage-3.1.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 grpc-google-iam-v1-0.14.2 grpcio-1.71.0 grpcio-status-1.71.0 h11-0.16.0 httpcore-1.0.9 httplib2-0.22.0 httpx-0.28.1 importlib-metadata-8.6.1 ipywidgets-8.1.7 isoduration-20.11.0 jinja2-3.1.6 json5-0.12.0 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.2 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 mistune-3.1.3 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.2 notebook-shim-0.2.4 numpy-1.26.4 oauthlib-3.2.2 opentelemetry-api-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 overrides-7.7.0 pandas-2.2.3 pandocfilters-1.5.1 prometheus-client-0.22.0 proto-plus-1.26.1 protobuf-5.29.4 pyarrow-20.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.22 pyparsing-3.2.3 python-dotenv-1.1.0 python-json-logger-3.3.0 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 requests-oauthlib-2.0.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.25.1 rsa-4.9.1 send2trash-1.8.3 setuptools-80.8.0 sniffio-1.3.1 soupsieve-2.7 terminado-0.18.1 tinycss2-1.4.0 tqdm-4.67.1 types-python-dateutil-2.9.0.20250516 typing_extensions-4.13.2 tzdata-2025.2 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14 wrapt-1.17.2 xlsxwriter-3.2.3 zipp-3.21.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Installed packages:\n",
            "Package                            Version\n",
            "---------------------------------- --------------\n",
            "anyio                              4.9.0\n",
            "appnope                            0.1.4\n",
            "argon2-cffi                        23.1.0\n",
            "argon2-cffi-bindings               21.2.0\n",
            "arrow                              1.3.0\n",
            "asttokens                          3.0.0\n",
            "async-lru                          2.0.5\n",
            "attrs                              25.3.0\n",
            "babel                              2.17.0\n",
            "beautifulsoup4                     4.13.4\n",
            "bleach                             6.2.0\n",
            "cachetools                         5.5.2\n",
            "certifi                            2025.4.26\n",
            "cffi                               1.17.1\n",
            "charset-normalizer                 3.4.2\n",
            "comm                               0.2.2\n",
            "db-dtypes                          1.4.3\n",
            "debugpy                            1.8.14\n",
            "decorator                          5.2.1\n",
            "defusedxml                         0.7.1\n",
            "Deprecated                         1.2.18\n",
            "executing                          2.2.0\n",
            "fastjsonschema                     2.21.1\n",
            "fqdn                               1.5.1\n",
            "google-api-core                    2.25.0rc1\n",
            "google-auth                        2.40.2\n",
            "google-auth-httplib2               0.2.0\n",
            "google-auth-oauthlib               1.2.2\n",
            "google-cloud-appengine-logging     1.6.1\n",
            "google-cloud-audit-log             0.3.2\n",
            "google-cloud-bigquery              3.33.0\n",
            "google-cloud-compute               1.30.0\n",
            "google-cloud-core                  2.4.3\n",
            "google-cloud-firestore             2.20.2\n",
            "google-cloud-logging               3.12.1\n",
            "google-cloud-pubsub                2.29.0\n",
            "google-cloud-storage               3.1.0\n",
            "google-crc32c                      1.7.1\n",
            "google-resumable-media             2.7.2\n",
            "googleapis-common-protos           1.70.0\n",
            "grpc-google-iam-v1                 0.14.2\n",
            "grpcio                             1.71.0\n",
            "grpcio-status                      1.71.0\n",
            "h11                                0.16.0\n",
            "httpcore                           1.0.9\n",
            "httplib2                           0.22.0\n",
            "httpx                              0.28.1\n",
            "idna                               3.10\n",
            "importlib_metadata                 8.6.1\n",
            "ipykernel                          6.29.5\n",
            "ipython                            9.2.0\n",
            "ipython_pygments_lexers            1.1.1\n",
            "ipywidgets                         8.1.7\n",
            "isoduration                        20.11.0\n",
            "jedi                               0.19.2\n",
            "Jinja2                             3.1.6\n",
            "json5                              0.12.0\n",
            "jsonpointer                        3.0.0\n",
            "jsonschema                         4.23.0\n",
            "jsonschema-specifications          2025.4.1\n",
            "jupyter                            1.1.1\n",
            "jupyter_client                     8.6.3\n",
            "jupyter-console                    6.6.3\n",
            "jupyter_core                       5.7.2\n",
            "jupyter-events                     0.12.0\n",
            "jupyter-lsp                        2.2.5\n",
            "jupyter_server                     2.16.0\n",
            "jupyter_server_terminals           0.5.3\n",
            "jupyterlab                         4.4.2\n",
            "jupyterlab_pygments                0.3.0\n",
            "jupyterlab_server                  2.27.3\n",
            "jupyterlab_widgets                 3.0.15\n",
            "MarkupSafe                         3.0.2\n",
            "matplotlib-inline                  0.1.7\n",
            "mistune                            3.1.3\n",
            "nbclient                           0.10.2\n",
            "nbconvert                          7.16.6\n",
            "nbformat                           5.10.4\n",
            "nest-asyncio                       1.6.0\n",
            "notebook                           7.4.2\n",
            "notebook_shim                      0.2.4\n",
            "numpy                              1.26.4\n",
            "oauthlib                           3.2.2\n",
            "opentelemetry-api                  1.33.1\n",
            "opentelemetry-sdk                  1.33.1\n",
            "opentelemetry-semantic-conventions 0.54b1\n",
            "overrides                          7.7.0\n",
            "packaging                          25.0\n",
            "pandas                             2.2.3\n",
            "pandocfilters                      1.5.1\n",
            "parso                              0.8.4\n",
            "pexpect                            4.9.0\n",
            "pip                                25.1.1\n",
            "platformdirs                       4.3.8\n",
            "prometheus_client                  0.22.0\n",
            "prompt_toolkit                     3.0.51\n",
            "proto-plus                         1.26.1\n",
            "protobuf                           5.29.4\n",
            "psutil                             7.0.0\n",
            "ptyprocess                         0.7.0\n",
            "pure_eval                          0.2.3\n",
            "pyarrow                            20.0.0\n",
            "pyasn1                             0.6.1\n",
            "pyasn1_modules                     0.4.2\n",
            "pycparser                          2.22\n",
            "Pygments                           2.19.1\n",
            "pyparsing                          3.2.3\n",
            "python-dateutil                    2.9.0.post0\n",
            "python-dotenv                      1.1.0\n",
            "python-json-logger                 3.3.0\n",
            "pytz                               2025.2\n",
            "PyYAML                             6.0.2\n",
            "pyzmq                              26.4.0\n",
            "referencing                        0.36.2\n",
            "requests                           2.32.3\n",
            "requests-oauthlib                  2.0.0\n",
            "rfc3339-validator                  0.1.4\n",
            "rfc3986-validator                  0.1.1\n",
            "rpds-py                            0.25.1\n",
            "rsa                                4.9.1\n",
            "Send2Trash                         1.8.3\n",
            "setuptools                         80.8.0\n",
            "six                                1.17.0\n",
            "sniffio                            1.3.1\n",
            "soupsieve                          2.7\n",
            "stack-data                         0.6.3\n",
            "terminado                          0.18.1\n",
            "tinycss2                           1.4.0\n",
            "tornado                            6.5.1\n",
            "tqdm                               4.67.1\n",
            "traitlets                          5.14.3\n",
            "types-python-dateutil              2.9.0.20250516\n",
            "typing_extensions                  4.13.2\n",
            "tzdata                             2025.2\n",
            "uri-template                       1.3.0\n",
            "urllib3                            2.4.0\n",
            "wcwidth                            0.2.13\n",
            "webcolors                          24.11.1\n",
            "webencodings                       0.5.1\n",
            "websocket-client                   1.8.0\n",
            "widgetsnbextension                 4.0.14\n",
            "wrapt                              1.17.2\n",
            "XlsxWriter                         3.2.3\n",
            "zipp                               3.21.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# check for existing venv, and use it if it exists. Otherwise, create fresh .venv\n",
        "venv_path = Path(\".venv\")\n",
        "if venv_path.exists():\n",
        "    print(\"Using the existing virtual environment...\")\n",
        "  #  shutil.rmtree(venv_path)\n",
        "\n",
        "else:\n",
        "    print(\"Creating fresh virtual environment...\")\n",
        "    !python -m venv .venv --clear\n",
        "\n",
        "# Use absolute paths to avoid any ambiguity\n",
        "venv_abs = venv_path.absolute()\n",
        "if sys.platform == \"win32\":\n",
        "    python_exe = venv_abs / \"Scripts\" / \"python.exe\"\n",
        "    pip_exe = venv_abs / \"Scripts\" / \"pip.exe\"\n",
        "else:\n",
        "    python_exe = venv_abs / \"bin\" / \"python\"\n",
        "    pip_exe = venv_abs / \"bin\" / \"pip\"\n",
        "\n",
        "# Install packages using explicit commands\n",
        "print(\"\\nInstalling packages...\")\n",
        "%pip install --upgrade pip\n",
        "%pip install requests\n",
        "\n",
        "# Test\n",
        "print(\"\\nTesting installation:\")\n",
        "!\"{python_exe}\" -c \"import requests; print(f'Success! Requests from: {{requests.__file__}}')\"\n",
        "%pip install -r requirements.txt\n",
        "# Show what's installed\n",
        "print(\"\\nInstalled packages:\")\n",
        "%pip list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud auth application-default login\n",
        "\n",
        "\"\"\"\n",
        "ENT Resident Case Processing System with Interactive UI\n",
        "\n",
        "This notebook combines:\n",
        "1. Interactive widgets for parameter selection and execution\n",
        "2. DataLoader class for retrieving data from various sources\n",
        "3. ResidentCaseProcessor class for data enrichment and transformation\n",
        "\n",
        "The result is a complete end-to-end system with a user-friendly interface.\n",
        "\"\"\"\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "from google.cloud import bigquery, storage\n",
        "import pandas as pd\n",
        "import json\n",
        "import openpyxl\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import display, Markdown, HTML\n",
        "from tqdm.notebook import tqdm\n",
        "from google.cloud.storage.blob import Blob\n",
        "from IPython.display import FileLink, display\n",
        "from io import BytesIO\n",
        "import traceback\n",
        "\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Class to load all source data from Google Cloud Storage and BigQuery.\"\"\"\n",
        "\n",
        "    def __init__(self, project_id=\"aif-usr-p-ent-ai-misc-3444\", bucket_name=\"shared-aif-bucket-3444\"):\n",
        "        \"\"\"Initialize the DataLoader with project and bucket information.\n",
        "\n",
        "        Args:\n",
        "            project_id: The Google Cloud project ID\n",
        "            bucket_name: The Google Cloud Storage bucket name\n",
        "        \"\"\"\n",
        "        self.project_id = project_id\n",
        "        self.bucket_name = bucket_name\n",
        "\n",
        "        # Set up time info\n",
        "        self.today = datetime.now()\n",
        "        self.start_date = (self.today - timedelta(days=7)).strftime('%Y-%m-%d')\n",
        "        self.end_date = self.today.strftime('%Y-%m-%d')\n",
        "        self.today_date = self.today.strftime('%Y-%m-%d')\n",
        "\n",
        "        # Define common blob names\n",
        "        self.cpt_blob_name = \"resident_cases/cpt_database.xlsx\"\n",
        "        self.consultant_blob_name = \"resident_cases/ENT_consultants.xlsx\"\n",
        "        self.resident_blob_name = \"resident_cases/resident_data.json\"\n",
        "        self.resident_blob_name2 = \"resident_cases/resident_data.json\"\n",
        "\n",
        "        # Initialize clients\n",
        "        self.bq_client = bigquery.Client(project=self.project_id)\n",
        "        self.storage_client = storage.Client()\n",
        "        self.bucket = self.storage_client.bucket(self.bucket_name)\n",
        "\n",
        "        # Progress update callback\n",
        "        self.progress_callback = None\n",
        "\n",
        "    def set_progress_callback(self, callback_function):\n",
        "        \"\"\"Set a callback function for progress updates.\n",
        "\n",
        "        Args:\n",
        "            callback_function: Function that takes (progress_value, status_text)\n",
        "        \"\"\"\n",
        "        self.progress_callback = callback_function\n",
        "\n",
        "    def update_progress(self, value, status_text=\"\"):\n",
        "        \"\"\"Update progress through callback if available.\n",
        "\n",
        "        Args:\n",
        "            value: Progress value (0-100)\n",
        "            status_text: Status message\n",
        "        \"\"\"\n",
        "        if self.progress_callback:\n",
        "            self.progress_callback(value, status_text)\n",
        "\n",
        "    def debug_print(self, message, level=\"INFO\"):\n",
        "        \"\"\"Print debug messages with timestamp and level.\n",
        "\n",
        "        Args:\n",
        "            message: The message to print\n",
        "            level: The log level (INFO, WARNING, ERROR)\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        if level == \"ERROR\":\n",
        "            print(f\"🔴 {timestamp} - ERROR: {message}\")\n",
        "        elif level == \"WARNING\":\n",
        "            print(f\"🟡 {timestamp} - WARNING: {message}\")\n",
        "        else:\n",
        "            print(f\"🔵 {timestamp} - {message}\")\n",
        "\n",
        "\n",
        "    def load_consultant_data(self):\n",
        "        \"\"\"Load consultant reference data from Google Cloud Storage.\n",
        "\n",
        "        Returns:\n",
        "            DataFrame: Consultant reference data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.update_progress(30, \"Loading consultant database...\")\n",
        "            consultant_blob = self.bucket.blob(self.consultant_blob_name)\n",
        "            consultant_bytes = consultant_blob.download_as_bytes()\n",
        "            df_consultants = pd.read_excel(BytesIO(consultant_bytes))\n",
        "            print(f\"✅ Loaded consultant database with {len(df_consultants)} rows.\")\n",
        "\n",
        "            # Show sample data\n",
        "         #   print(\"\\n📊 Consultant DataFrame columns:\", df_consultants.columns.tolist())\n",
        "         #   display(df_consultants.head(3))\n",
        "\n",
        "            self.update_progress(35, \"Consultant database loaded successfully\")\n",
        "            return df_consultants\n",
        "\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error loading consultant data: {str(e)}\", \"ERROR\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def load_cpt_data(self):\n",
        "        \"\"\"Load CPT reference data from Google Cloud Storage.\n",
        "\n",
        "        Returns:\n",
        "            DataFrame: CPT reference data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.update_progress(20, \"Loading CPT database...\")\n",
        "            cpt_blob = self.bucket.blob(self.cpt_blob_name)\n",
        "            cpt_bytes = cpt_blob.download_as_bytes()\n",
        "            df_cpt = pd.read_excel(BytesIO(cpt_bytes))\n",
        "            print(f\"✅ Loaded CPT database with {len(df_cpt)} rows.\")\n",
        "\n",
        "            # Show sample data\n",
        "            self.update_progress(25, \"CPT database loaded successfully\")\n",
        "            return df_cpt\n",
        "\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error loading CPT data: {str(e)}\", \"ERROR\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def load_resident_data(self):\n",
        "        \"\"\"Load resident data from Google Cloud Storage.\n",
        "\n",
        "        Returns:\n",
        "            list: List of resident dictionaries\n",
        "        \"\"\"\n",
        "        try:\n",
        "            resident_blob = self.bucket.blob(self.resident_blob_name)\n",
        "            json_bytes = resident_blob.download_as_bytes()\n",
        "            dict_residents = json.loads(json_bytes.decode('utf-8'))\n",
        "            print(f\"✅ Loaded resident data with {len(dict_residents)} entries.\")\n",
        "\n",
        "            # Show sample data\n",
        "            sample_keys = list(dict_residents[0].keys())[:5]  # Show first 5 keys\n",
        "            return dict_residents\n",
        "\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error loading resident data: {str(e)}\", \"ERROR\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def create_residents_from_bigquery(self):\n",
        "        \"\"\"Create resident data from BigQuery.\n",
        "\n",
        "        Returns:\n",
        "            list: List of resident dictionaries with updated information\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"📊 Querying resident data from BigQuery...\")\n",
        "\n",
        "            # The SQL query to get resident information\n",
        "            query = \"\"\"\n",
        "            SELECT\n",
        "            PR.practitioner_display,\n",
        "            PR.telecom3_value AS email,\n",
        "            PR.telecom1_value AS phone_number,\n",
        "            DHP.PROVIDER_LAN_ID AS LAN_ID,\n",
        "            DHP.PROVIDER_PERSON_ID AS Person_ID,\n",
        "            DHP.PROVIDER_FIRST_NAME AS First_name,\n",
        "            DHP.PROVIDER_LAST_NAME AS Last_name\n",
        "\n",
        "            FROM `ml-mps-adl-intfhr-phi-p-3b6e.phi_current_fhir_us_p.PractitionerRole` PR\n",
        "\n",
        "            RIGHT JOIN\n",
        "            `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_HEALTHCARE_PROVIDER` DHP\n",
        "            ON (PR.telecom3_value = DHP.PROVIDER_EMAIL_ADDRESS)\n",
        "\n",
        "            WHERE specialty_coding_display = (\"Otorhinolaryngology\")\n",
        "            AND code_text IN (\"Resident\",\"Fellow\", \"Resident Unlicensed DEA\")\n",
        "            AND telecom1_value LIKE (\"%507%\")\n",
        "            AND telecom2_value LIKE (\"%507%\")\n",
        "            AND DHP.PROVIDER_NPI IS NOT NULL\n",
        "            AND DHP.PROVIDER_NPI != ''\n",
        "            AND DHP.PROVIDER_PERSON_ID IS NOT NULL\n",
        "            AND DHP.PROVIDER_PERSON_ID != ''\n",
        "            AND PR.active IS TRUE\n",
        "            \"\"\"\n",
        "\n",
        "            # Execute the query\n",
        "            query_job = self.bq_client.query(query)\n",
        "            results = query_job.result()\n",
        "\n",
        "            # Convert to pandas DataFrame for easier processing\n",
        "            df = results.to_dataframe()\n",
        "            print(f\"✅ Retrieved {len(df)} resident records from BigQuery.\")\n",
        "\n",
        "            # Create list of dictionaries\n",
        "            resident_dict2 = []\n",
        "            for _, row in df.iterrows():\n",
        "                resident = {\n",
        "                    \"First name\": row[\"First_name\"],\n",
        "                    \"Last name\": row[\"Last_name\"],\n",
        "                    \"LAN_ID\": row[\"LAN_ID\"],\n",
        "                    \"Employee_ID\": row[\"Person_ID\"],\n",
        "                    \"Email\": row[\"email\"],\n",
        "                    \"Phone_number\": row[\"phone_number\"]\n",
        "                }\n",
        "                resident_dict2.append(resident)\n",
        "\n",
        "            print(f\"✅ Created resident_dict2 with {len(resident_dict2)} entries.\")\n",
        "\n",
        "            # Show sample data\n",
        "            if resident_dict2:\n",
        "                sample_keys = list(resident_dict2[0].keys())\n",
        "            return resident_dict2\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"🔴 Error creating resident data from BigQuery: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def combine_and_save_resident_data(self):\n",
        "        \"\"\"Combine resident data from both sources and save to Google Cloud Storage.\"\"\"\n",
        "        try:\n",
        "            # Load existing resident data\n",
        "            dict_residents = self.load_resident_data()\n",
        "\n",
        "            # Create new resident data from BigQuery\n",
        "            resident_dict2 = self.create_residents_from_bigquery()\n",
        "\n",
        "            # Create an email-to-record mapping for faster lookups\n",
        "            email_to_resident = {r.get(\"Email\", \"\").lower(): r for r in dict_residents if r.get(\"Email\")}\n",
        "\n",
        "            # Track statistics for reporting\n",
        "            updated_count = 0\n",
        "            added_count = 0\n",
        "\n",
        "            # Process each resident from BigQuery data\n",
        "            for new_resident in resident_dict2:\n",
        "                email = new_resident.get(\"Email\", \"\").lower()\n",
        "                if not email:\n",
        "                    continue\n",
        "\n",
        "                if email in email_to_resident:\n",
        "                    # Update existing resident record with new fields\n",
        "                    existing_resident = email_to_resident[email]\n",
        "                    record_modified = False\n",
        "\n",
        "                    for key, value in new_resident.items():\n",
        "                        # Only update if the key doesn't exist or has an empty value\n",
        "                        if key not in existing_resident or not existing_resident[key]:\n",
        "                            if value:  # Only update if the new value is not empty\n",
        "                                existing_resident[key] = value\n",
        "                                record_modified = True\n",
        "\n",
        "                    # Only increment counter if at least one field was updated\n",
        "                    if record_modified:\n",
        "                        updated_count += 1\n",
        "                else:\n",
        "                    # Add new resident to the list\n",
        "                    dict_residents.append(new_resident)\n",
        "                    email_to_resident[email] = new_resident\n",
        "                    added_count += 1\n",
        "\n",
        "            print(f\"✅ Updated {updated_count} existing resident records\")\n",
        "            print(f\"✅ Added {added_count} new resident records\")\n",
        "            print(f\"✅ Total resident count: {len(dict_residents)}\")\n",
        "\n",
        "            # Convert to JSON\n",
        "            json_data = json.dumps(dict_residents, indent=2)\n",
        "\n",
        "            # Upload to GCS\n",
        "            resident_blob = self.bucket.blob(self.resident_blob_name2)\n",
        "            resident_blob.upload_from_string(json_data, content_type=\"application/json\")\n",
        "\n",
        "            print(f\"✅ Combined resident data saved to gs://{self.bucket_name}/{self.resident_blob_name2}\")\n",
        "\n",
        "            return dict_residents\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"🔴 Error combining and saving resident data: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "\n",
        "    def generate_query(self, start_date, end_date, selected_emails, include_op_notes=False, include_path_reports=False):\n",
        "        \"\"\"Generate BigQuery SQL query based on parameters.\n",
        "\n",
        "        Args:\n",
        "            start_date: Start date for query (YYYY-MM-DD)\n",
        "            end_date: End date for query (YYYY-MM-DD)\n",
        "            selected_emails: List of emails to filter by\n",
        "            include_op_notes: Whether to include operation notes\n",
        "            include_path_reports: Whether to include pathology reports\n",
        "\n",
        "        Returns:\n",
        "            str: SQL query\n",
        "        \"\"\"\n",
        "        # Format the emails for SQL\n",
        "        email_list = \",\\n        \".join([f\"'{email.lower()}'\" for email in selected_emails])\n",
        "\n",
        "        # Conditionally include Operation Notes\n",
        "        op_note_field = \"FACT_CLINICAL_DOCUMENTS.CLINICAL_DOCUMENT_TEXT AS Op_note,\" if include_op_notes else \"\"\n",
        "\n",
        "        # Conditionally include Pathology Reports\n",
        "        path_report_field = \"fp.SPECIMEN_NOTE AS Path_report,\" if include_path_reports else \"\"\n",
        "\n",
        "        return f\"\"\"\n",
        "    -- Define provider emails at the top\n",
        "    WITH Provider_Emails AS (\n",
        "        SELECT email FROM UNNEST([\n",
        "            {email_list}\n",
        "        ]) AS email\n",
        "    ),\n",
        "\n",
        "    -- Define valid CPT codes at the top\n",
        "    Valid_CPT_Code_List AS (\n",
        "        SELECT code FROM UNNEST(['10005','10021','11420','11421','11422','11423','11424','11426','11440','11441','11442','11443','11444','11446','11620','11621','11622','11623','11624','11626','11640','11641','11642','11643','11644','11646','13120','13121','13122','13131','13132','13133','13151','13152','13153','14000','14001','14020','14021','14040','14041','14060','14061','14301','14302','15002','15003','15004','15005','15100','15101','15110','15111','15115','15116','15120','15121','15130','15135','15220','15221','15240','15241','15260','15261','15572','15574','15576','15610','15620','15630','15731','15734','15740','15756','15757','15758','15760','15770','15775','15777','15780','15781','15782','15783','15786','15788','15789','15792','15793','15819','15820','15821','15822','15823','15824','15825','15826','15828','15829','15840','15841','15842','15845','15876','20900','20902','20910','20912','20922','20955','20969','20970','21110','21210','21215','21230','21235','21244','21245','21280','21282','21315','21320','21325','21330','21335','21336','21337','21338','21343','21344','21345','21346','21347','21348','21355','21356','21360','21365','21366','21385','21386','21387','21390','21395','21401','21406','21407','21408','21421','21422','21423','21431','21432','21433','21435','21436','21440','21445','21451','21452','21453','21454','21461','21462','21465','21470','21550','21552','21554','21555','21556','21557','21558','21685','21720','30000','30020','30100','30110','30115','30117','30118','30124','30125','30130','30140','30150','30160','30200','30220','30300','30310','30400','30410','30430','30435','30450','30460','30462','30465','30468','30520','30540','30545','30560','30580','30600','30620','30630','30801','30802','30901','30903','30905','30906','30915','30920','31000','31020','31030','31032','31040','31070','31075','31080','31081','31084','31085','31086','31087','31205','31225','31230','31237','31238','31239','31240','31254','31255','31256','31267','31276','31287','31288','31290','31291','31292','31293','31294','31295','31296','31297','31300','31360','31367','31370','31375','31380','31382','31390','31395','31420','31520','31525','31526','31527','31528','31530','31531','31535','31536','31540','31541','31545','31551','31552','31553','31554','31560','31561','31570','31571','31572','31573','31574','31575','31576','31577','31578','31579','31580','31584','31587','31590','31591','31592','31600','31601','31605','31610','31611','31613','31614','31615','31622','31623','31624','31625','31630','31631','31635','31636','31638','31640','31641','31750','31780','31800','35180','35188','35201','35701','35800','35875','35876','38380','38500','38510','38520','38542','38550','38555','38700','38720','38724','40490','40500','40510','40520','40525','40527','40530','40650','40700','40701','40702','40720','40761','40800','40801','40804','40805','40808','40810','40812','40814','40840','40844','41000','41005','41006','41007','41008','41009','41010','41100','41108','41110','41112','41113','41116','41120','41130','41140','41150','41153','41510','41512','41520','41530','41823','41825','41874','42000','42100','42104','42106','42120','42140','42145','42160','42200','42205','42210','42215','42220','42225','42226','42227','42235','42260','42281','42310','42330','42335','42340','42405','42408','42409','42410','42415','42420','42425','42440','42450','42500','42505','42507','42550','42600','42650','42660','42665','42700','42720','42800','42808','42809','42810','42815','42825','42826','42830','42831','42835','42836','42842','42870','42890','42892','42894','42900','42950','42953','42955','42960','42962','42975','43020','43030','43100','43116','43124','43130','43180','43191','43192','43193','43194','43195','43196','43197','43198','43200','43201','43202','43215','43220','43226','43410','43496','60220','60225','60240','60252','60260','60270','60271','60280','60281','60500','60502','60512','60600','60605','61580','61581','61584','61585','61586','61590','61596','61598','61605','61607','61611','61615','61618','64568','64582','64584','64868','64885','67900','67901','67911','67912','67914','67916','67917','67950','68720','68815','69000','69005','69020','69100','69105','69110','69120','69140','69145','69150','69200','69205','69222','69300','69310','69320','69420','69421','69424','69433','69436','69440','69501','69502','69505','69511','69530','69535','69540','69550','69552','69554','69601','69602','69603','69610','69620','69631','69632','69633','69650','69660','69661','69662','69666','69667','69670','69676','69700','69705','69710','69711','69714','69716','69717','69720','69725','69726','69727','69740','69745','69801','69805','69806','69905','69915','69930','69950','69955','69960','69970','95805','95806','95807','95808','95810','95811','95992']) AS code\n",
        "    ),\n",
        "\n",
        "    -- Break down the procedures with their bilateral codes\n",
        "    Procedure_Details_With_Bilateral AS (\n",
        "        SELECT\n",
        "            fscp.SURGICAL_CASE_FPK,\n",
        "            fscp.SURGICAL_PROCEDURE_DK,\n",
        "            fscp.SURGICAL_PROCEDURE_ORDERED_DESCRIPTION,\n",
        "            dsp.SURGICAL_PROCEDURE_DESCRIPTION,\n",
        "            fscp.SURGICAL_PROCEDURE_BILATERAL_CODE\n",
        "        FROM `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.FACT_SURGICAL_CASE_PROCEDURE` AS fscp\n",
        "        JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_SURGICAL_PROCEDURE` AS dsp\n",
        "            ON fscp.SURGICAL_PROCEDURE_DK = dsp.SURGICAL_PROCEDURE_DK\n",
        "    ),\n",
        "\n",
        "    Procedure_Aggregates AS (\n",
        "        SELECT\n",
        "            fscp.SURGICAL_CASE_FPK,\n",
        "            STRING_AGG(DISTINCT fscp.SURGICAL_PROCEDURE_ORDERED_DESCRIPTION, '; ') AS all_written_procedures,\n",
        "            STRING_AGG(DISTINCT CONCAT(dsp.SURGICAL_PROCEDURE_DESCRIPTION, ' (', COALESCE(fscp.SURGICAL_PROCEDURE_BILATERAL_CODE, 'N/A'), ')'), '; ') AS written_procedures_summarized,\n",
        "            STRING_AGG(DISTINCT fscp.SURGICAL_PROCEDURE_BILATERAL_CODE, '; ') AS all_bilateral_codes\n",
        "        FROM `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.FACT_SURGICAL_CASE_PROCEDURE` AS fscp\n",
        "        JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_SURGICAL_PROCEDURE` AS dsp\n",
        "            ON fscp.SURGICAL_PROCEDURE_DK = dsp.SURGICAL_PROCEDURE_DK\n",
        "        GROUP BY fscp.SURGICAL_CASE_FPK\n",
        "    ),\n",
        "\n",
        "    -- Extract procedures and filter by both FACT_PROCEDURES and DIM_PROCEDURE_CODE criteria\n",
        "    Matching_Procedures AS (\n",
        "        SELECT\n",
        "            fsc.SURGICAL_CASE_FPK,\n",
        "            fp.procedure_code_DK,\n",
        "            fp.procedure_code,\n",
        "            fp.procedure_method_code,\n",
        "            dpc.PROCEDURE_NAME,\n",
        "            dpc.PROCEDURE_DESCRIPTION,\n",
        "            dpc.PROCEDURE_CODE AS dim_procedure_code,\n",
        "            dpc.PROCEDURE_CATEGORY\n",
        "        FROM `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.FACT_SURGICAL_CASE` AS fsc\n",
        "        JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.FACT_PROCEDURES` AS fp\n",
        "            ON fsc.SURGICAL_CASE_DTM = fp.Procedure_dtm\n",
        "            AND fsc.PATIENT_DK = fp.patient_dk\n",
        "            AND fp.procedure_method_code = 'CPT(R)'\n",
        "        JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_PROCEDURE_CODE` AS dpc\n",
        "            ON fp.procedure_code_DK = dpc.PROCEDURE_CODE_DK\n",
        "            AND dpc.PROCEDURE_METHOD_CODE IN ('CPT(R)')\n",
        "            AND dpc.PROCEDURE_CATEGORY IN (\n",
        "                'PR DIGESTIVE SYSTEM SERVICES',\n",
        "                'PR ENDOCRINE SYSTEM SERVICES',\n",
        "                'PR HEMIC AND LYMPHATIC SYSTEM SERVICES',\n",
        "                'PR INTEGUMENTARY SYSTEM SERVICES',\n",
        "                'PR MEDIASTINUM AND DIAPHRAGM SERVICES',\n",
        "                'PR MUSCULOSKELETAL SERVICES',\n",
        "                'PR NERVOUS SYSTEM SERVICES',\n",
        "                'PR OPHTHALMOLOGY SERVICES',\n",
        "                'PR OTORHINOLARYNGOLOGIC',\n",
        "                'PR RESPIRATORY SYSTEM SERVICES',\n",
        "                'PR AUDITORY SYSTEM SERVICES'\n",
        "            )\n",
        "    ),\n",
        "\n",
        "    -- Aggregate the filtered procedures by SURGICAL_CASE_FPK\n",
        "    Procedure_Details AS (\n",
        "        SELECT\n",
        "            SURGICAL_CASE_FPK,\n",
        "            STRING_AGG(DISTINCT CAST(procedure_code_DK AS STRING), '; ') AS procedure_code_DKs,\n",
        "            STRING_AGG(DISTINCT procedure_code, ', ') AS procedure_codes,\n",
        "            STRING_AGG(DISTINCT procedure_method_code, '; ') AS procedure_method_codes,\n",
        "            STRING_AGG(DISTINCT PROCEDURE_NAME, '; ') AS procedure_names,\n",
        "            STRING_AGG(DISTINCT PROCEDURE_DESCRIPTION, '; ') AS procedure_descriptions,\n",
        "            STRING_AGG(DISTINCT dim_procedure_code, ', ') AS dim_procedure_codes,\n",
        "            STRING_AGG(DISTINCT PROCEDURE_CATEGORY, '; ') AS procedure_categories\n",
        "        FROM Matching_Procedures\n",
        "        GROUP BY SURGICAL_CASE_FPK\n",
        "    ),\n",
        "\n",
        "    -- Modified CTE to use the Valid_CPT_Code_List\n",
        "    Valid_CPT_Codes AS (\n",
        "        SELECT\n",
        "            mp.SURGICAL_CASE_FPK,\n",
        "            STRING_AGG(DISTINCT mp.procedure_code, ', ') AS valid_CPT_codes\n",
        "        FROM Matching_Procedures mp\n",
        "        JOIN Valid_CPT_Code_List vcl\n",
        "            ON mp.procedure_code = vcl.code\n",
        "        GROUP BY mp.SURGICAL_CASE_FPK\n",
        "    ),\n",
        "\n",
        "    -- New CTE to aggregate all providers by SURGICAL_CASE_FPK\n",
        "    All_Providers AS (\n",
        "        SELECT\n",
        "            dsprb.SURGICAL_CASE_FPK,\n",
        "            STRING_AGG(DISTINCT dhp.PROVIDER_LAST_NAME, '; ') AS all_providers\n",
        "        FROM `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_SURGICAL_PROVIDER_ROLE_SERVICE_BRIDGE` AS dsprb\n",
        "        JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_HEALTHCARE_PROVIDER` AS dhp\n",
        "            ON dhp.PROVIDER_DK = dsprb.PROVIDER_DK\n",
        "        WHERE LOWER(dhp.PROVIDER_SPECIALTY_DESCRIPTION) IN ('otolaryngology', 'otorhinolaryngology')\n",
        "        GROUP BY dsprb.SURGICAL_CASE_FPK\n",
        "    )\n",
        "\n",
        "    SELECT DISTINCT\n",
        "        fsc.SURGICAL_CASE_FPK AS SURGICAL_CASE_FPK,\n",
        "        PAT_DIM_PATIENT.PATIENT_CLINIC_NUMBER AS MRN,\n",
        "        dhp.PROVIDER_FIRST_NAME AS Resident_first_name,\n",
        "        dhp.PROVIDER_LAST_NAME AS Resident_last_name,\n",
        "        dhp.PROVIDER_EMAIL_ADDRESS AS Prov_email,\n",
        "        fsc.SURGICAL_CASE_DTM AS Surgery_date,\n",
        "        dhp_primary.PROVIDER_LAST_NAME AS Primary_surgeon,\n",
        "        ap.all_providers AS All_providers,\n",
        "        dspr.SURGICAL_PROVIDER_ROLE_DESCRIPTION AS Role,\n",
        "        DATE_DIFF(EXTRACT(DATE FROM fsc.SURGICAL_CASE_DTM), PAT_DIM_PATIENT.PATIENT_BIRTH_DATE, DAY) AS Pt_Age_In_Days,\n",
        "        proc_agg.all_written_procedures,\n",
        "        proc_agg.written_procedures_summarized,\n",
        "        proc_agg.all_bilateral_codes,\n",
        "        pd.procedure_descriptions AS Procedure_descriptions,\n",
        "        pd.procedure_codes AS CPT_codes,\n",
        "        vcpt.valid_CPT_codes,\n",
        "        {op_note_field}\n",
        "        {path_report_field}\n",
        "\n",
        "    FROM `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.FACT_SURGICAL_CASE` AS fsc\n",
        "    JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_SURGICAL_PROVIDER_ROLE_SERVICE_BRIDGE` AS dsprb\n",
        "        ON fsc.SURGICAL_CASE_FPK = dsprb.SURGICAL_CASE_FPK\n",
        "    JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_SURGICAL_PROVIDER_ROLE` AS dspr\n",
        "        ON dspr.SURGICAL_PROVIDER_ROLE_DK = dsprb.SURGICAL_PROVIDER_ROLE_DK\n",
        "    JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_HEALTHCARE_PROVIDER` AS dhp\n",
        "        ON dhp.PROVIDER_DK = dsprb.PROVIDER_DK\n",
        "    JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_HEALTHCARE_PROVIDER` AS dhp_primary\n",
        "        ON dhp_primary.PROVIDER_DK = fsc.PRIMARY_PROVIDER_DK\n",
        "    JOIN `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_PATIENT` AS PAT_DIM_PATIENT\n",
        "        ON fsc.PATIENT_DK = PAT_DIM_PATIENT.PATIENT_DK\n",
        "    JOIN Procedure_Aggregates AS proc_agg\n",
        "        ON fsc.SURGICAL_CASE_FPK = proc_agg.SURGICAL_CASE_FPK\n",
        "    LEFT JOIN Procedure_Details AS pd\n",
        "        ON fsc.SURGICAL_CASE_FPK = pd.SURGICAL_CASE_FPK\n",
        "    LEFT JOIN Valid_CPT_Codes AS vcpt\n",
        "        ON fsc.SURGICAL_CASE_FPK = vcpt.SURGICAL_CASE_FPK\n",
        "    LEFT JOIN All_Providers AS ap\n",
        "        ON fsc.SURGICAL_CASE_FPK = ap.SURGICAL_CASE_FPK\n",
        "    LEFT JOIN\n",
        "    `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.DIM_SURGICAL_CASE_NOTE_BRIDGE` DSC_note_bridge\n",
        "    ON (fsc.SURGICAL_CASE_FPK = DSC_note_bridge.SURGICAL_CASE_FPK)\n",
        "\n",
        "    LEFT JOIN\n",
        "    `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.FACT_CLINICAL_DOCUMENTS` FACT_CLINICAL_DOCUMENTS\n",
        "    ON (DSC_note_bridge.CLINICAL_DOCUMENT_ID = FACT_CLINICAL_DOCUMENTS.CLINICAL_DOCUMENT_ID)\n",
        "\n",
        "\n",
        "    LEFT JOIN\n",
        "    `ml-mps-adl-intudp-phi-p-d5cb.phi_udpwh_etl_us_p.FACT_PATHOLOGY` fp\n",
        "    ON (fsc.PATIENT_DK = fp.PATIENT_DK AND fp.SPECIMEN_COLLECTION_DATE_DK = fsc.SURGICAL_CASE_DATE_DK)\n",
        "\n",
        "\n",
        "    WHERE LOWER(dhp.PROVIDER_EMAIL_ADDRESS) IN (SELECT email FROM Provider_Emails)\n",
        "    -- AND LOWER(dhp.PROVIDER_LOCATION_SITE_NAME) = 'rochester, minnesota'\n",
        "\n",
        "    AND (fsc.SURGICAL_CASE_DTM BETWEEN '{start_date}' AND '{end_date}')\n",
        "        \"\"\"\n",
        "\n",
        "    def query_surgical_cases(self, start_date, end_date, selected_emails, include_op_notes=False, include_path_reports=False):\n",
        "        \"\"\"Query BigQuery for surgical case data based on parameters.\n",
        "\n",
        "        Args:\n",
        "            start_date: Start date for query (YYYY-MM-DD)\n",
        "            end_date: End date for query (YYYY-MM-DD)\n",
        "            selected_emails: List of emails to filter by\n",
        "            include_op_notes: Whether to include operation notes\n",
        "            include_path_reports: Whether to include pathology reports\n",
        "\n",
        "        Returns:\n",
        "            DataFrame: Surgical case data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.update_progress(40, \"Generating SQL query...\")\n",
        "\n",
        "            # Generate query based on parameters\n",
        "            query = self.generate_query(\n",
        "                start_date,\n",
        "                end_date,\n",
        "                selected_emails,\n",
        "                include_op_notes,\n",
        "                include_path_reports\n",
        "            )\n",
        "\n",
        "            self.update_progress(50, \"Executing BigQuery query...\")\n",
        "            print(\"Running resident case log query...\")\n",
        "\n",
        "            # Execute query\n",
        "            query_job = self.bq_client.query(query)\n",
        "\n",
        "            # Wait for the query to complete\n",
        "            self.update_progress(60, \"Query running... Please wait...\")\n",
        "            results = query_job.result()  # This blocks until the query is complete\n",
        "\n",
        "            # Convert results to DataFrame\n",
        "            self.update_progress(70, \"Query complete, fetching results...\")\n",
        "            df_surgical = results.to_dataframe()\n",
        "\n",
        "            print(f\"✅ Retrieved {len(df_surgical)} surgical cases.\")\n",
        "            self.update_progress(75, f\"Retrieved {len(df_surgical)} surgical cases\")\n",
        "\n",
        "            # Rename columns to match expected format if needed\n",
        "            if 'Resident_email' in df_surgical.columns:\n",
        "                df_surgical = df_surgical.rename(columns={'Resident_email': 'Prov_email'})\n",
        "\n",
        "            return df_surgical\n",
        "\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error querying surgical cases: {str(e)}\", \"ERROR\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def create_combined_dataframe(self, start_date, end_date, selected_emails, include_op_notes=False, include_path_reports=False):\n",
        "        \"\"\"Create the combined dataframe that merges all necessary source data.\n",
        "\n",
        "        Args:\n",
        "            start_date: Start date for query (YYYY-MM-DD)\n",
        "            end_date: End date for query (YYYY-MM-DD)\n",
        "            selected_emails: List of emails to filter by\n",
        "            include_op_notes: Whether to include operation notes\n",
        "            include_path_reports: Whether to include pathology reports\n",
        "\n",
        "        Returns:\n",
        "            tuple: (combined_df, df_cpt, df_consultants) - All dataframes needed for processing\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load all reference data\n",
        "            df_cpt = self.load_cpt_data()\n",
        "            df_consultants = self.load_consultant_data()\n",
        "\n",
        "            # Query surgical cases\n",
        "            df_surgical = self.query_surgical_cases(\n",
        "                start_date,\n",
        "                end_date,\n",
        "                selected_emails,\n",
        "                include_op_notes,\n",
        "                include_path_reports\n",
        "            )\n",
        "\n",
        "            # For this implementation, we're assuming df_surgical already has all the needed\n",
        "            # resident information from the BigQuery join. If not, we could load residents\n",
        "            # and merge them here.\n",
        "            combined_df = df_surgical\n",
        "\n",
        "            print(f\"✅ Created combined dataframe with {len(combined_df)} rows.\")\n",
        "\n",
        "            return combined_df, df_cpt, df_consultants\n",
        "\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error creating combined dataframe: {str(e)}\", \"ERROR\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "    def save_dataframe(self, df, filename, sheet_name=\"Data\"):\n",
        "        \"\"\"Save a dataframe to Google Cloud Storage as Excel.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to save\n",
        "            filename: Name of the file (without path)\n",
        "            sheet_name: Name of the Excel sheet\n",
        "\n",
        "        Returns:\n",
        "            str: Local file path where the data was saved\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.update_progress(95, \"Saving Excel file...\")\n",
        "\n",
        "            # Local path\n",
        "            local_path = filename\n",
        "\n",
        "            # Save locally first\n",
        "            with pd.ExcelWriter(local_path, engine=\"openpyxl\") as writer:\n",
        "                df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
        "\n",
        "            # Upload to GCS\n",
        "            self.update_progress(98, \"Uploading to Google Cloud Storage...\")\n",
        "            blob_name = f\"resident_cases/{filename}\"\n",
        "            blob = self.bucket.blob(blob_name)\n",
        "            blob.upload_from_filename(local_path)\n",
        "\n",
        "            print(f\"💾 DataFrame saved locally at: {local_path}\")\n",
        "            print(f\"📁 DataFrame uploaded to gs://{self.bucket_name}/{blob_name}\")\n",
        "\n",
        "            self.update_progress(100, \"File saved and uploaded successfully!\")\n",
        "\n",
        "            return local_path\n",
        "\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error saving dataframe: {str(e)}\", \"ERROR\")\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "\n",
        "class ResidentCaseProcessor:\n",
        "    \"\"\"Class to process resident case data with additional enrichment.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize processor with tracking information.\"\"\"\n",
        "        # Initialize tracking dictionaries\n",
        "        self.cpt_tracking = {\n",
        "            \"total_codes_processed\": 0,\n",
        "            \"codes_with_matches\": 0,\n",
        "            \"codes_without_matches\": 0,\n",
        "            \"rows_with_cpt_codes\": 0,\n",
        "            \"errors\": 0\n",
        "        }\n",
        "\n",
        "        # Set up time info for filename generation\n",
        "        self.today = datetime.now()\n",
        "        self.today_date = self.today.strftime('%Y-%m-%d')\n",
        "\n",
        "        # Progress update callback\n",
        "        self.progress_callback = None\n",
        "\n",
        "    def set_progress_callback(self, callback_function):\n",
        "        \"\"\"Set a callback function for progress updates.\n",
        "\n",
        "        Args:\n",
        "            callback_function: Function that takes (progress_value, status_text)\n",
        "        \"\"\"\n",
        "        self.progress_callback = callback_function\n",
        "\n",
        "    def update_progress(self, value, status_text=\"\"):\n",
        "        \"\"\"Update progress through callback if available.\n",
        "\n",
        "        Args:\n",
        "            value: Progress value (0-100)\n",
        "            status_text: Status message\n",
        "        \"\"\"\n",
        "        if self.progress_callback:\n",
        "            self.progress_callback(value, status_text)\n",
        "\n",
        "    def debug_print(self, message, level=\"INFO\"):\n",
        "        \"\"\"Print debug messages with timestamp and level.\n",
        "\n",
        "        Args:\n",
        "            message: The message to print\n",
        "            level: The log level (INFO, WARNING, ERROR)\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "        if level == \"ERROR\":\n",
        "            print(f\"🔴 {timestamp} - ERROR: {message}\")\n",
        "        elif level == \"WARNING\":\n",
        "            print(f\"🟡 {timestamp} - WARNING: {message}\")\n",
        "        else:\n",
        "            print(f\"🔵 {timestamp} - {message}\")\n",
        "\n",
        "    def prepare_cpt_dataframe(self, df_cpt):\n",
        "        \"\"\"Prepare CPT dataframe for matching.\n",
        "\n",
        "        Args:\n",
        "            df_cpt: The CPT reference dataframe\n",
        "\n",
        "        Returns:\n",
        "            DataFrame: Prepared CPT dataframe\n",
        "        \"\"\"\n",
        "        # Check if df_cpt has the expected columns\n",
        "        if 'CPT_CODE' not in df_cpt.columns:\n",
        "            self.debug_print(\"'CPT_CODE' column not found in df_cpt.\", \"WARNING\")\n",
        "            print(\"Available columns in df_cpt:\", df_cpt.columns.tolist())\n",
        "            # Try to find similar column names that might be the CPT code column\n",
        "            potential_cpt_columns = [col for col in df_cpt.columns if 'CPT' in col or 'cpt' in col.lower()]\n",
        "            if potential_cpt_columns:\n",
        "                print(f\"Potential CPT code columns found: {potential_cpt_columns}\")\n",
        "                # Use the first potential match\n",
        "                print(f\"Using '{potential_cpt_columns[0]}' as the CPT code column\")\n",
        "                df_cpt.rename(columns={potential_cpt_columns[0]: 'CPT_CODE'}, inplace=True)\n",
        "            else:\n",
        "                self.debug_print(\"No CPT_CODE column found and no suitable alternative identified\", \"ERROR\")\n",
        "                raise ValueError(\"CPT_CODE column not found in df_cpt\")\n",
        "\n",
        "        if 'Modified_CPT' not in df_cpt.columns:\n",
        "            self.debug_print(\"'Modified_CPT' column not found in df_cpt.\", \"WARNING\")\n",
        "            print(\"Available columns in df_cpt:\", df_cpt.columns.tolist())\n",
        "            # Try to find similar column names that might be the Modified CPT column\n",
        "            potential_mod_columns = [col for col in df_cpt.columns if 'MOD' in col.upper() or 'MODIFIED' in col.upper()]\n",
        "            if potential_mod_columns:\n",
        "                print(f\"Potential Modified CPT columns found: {potential_mod_columns}\")\n",
        "                # Use the first potential match\n",
        "                print(f\"Using '{potential_mod_columns[0]}' as the Modified CPT column\")\n",
        "                df_cpt.rename(columns={potential_mod_columns[0]: 'Modified_CPT'}, inplace=True)\n",
        "            else:\n",
        "                # If no modified column is found, create one with the same values as CPT_CODE\n",
        "                print(\"Creating 'Modified_CPT' column as a copy of 'CPT_CODE'\")\n",
        "                df_cpt['Modified_CPT'] = df_cpt['CPT_CODE']\n",
        "\n",
        "        # Convert CPT_CODE to string type in the CPT dataframe for easier matching\n",
        "        # Also clean delimiters from the reference data\n",
        "        df_cpt['CPT_CODE'] = df_cpt['CPT_CODE'].astype(str).str.strip()\n",
        "        df_cpt['CPT_CODE_clean'] = df_cpt['CPT_CODE'].str.replace(',', '').str.replace(';', '').str.replace('.', '').str.strip()\n",
        "\n",
        "        # Display the first few rows of the CPT dataframe after any modifications\n",
        "       # print(\"\\n📊 CPT DataFrame after column adjustments:\")\n",
        "       # display(df_cpt.head(3))\n",
        "\n",
        "        return df_cpt\n",
        "\n",
        "    def process_cpt_codes(self, processed_df, df_cpt, idx):\n",
        "        \"\"\"Process CPT codes for a single row.\n",
        "\n",
        "        Args:\n",
        "            processed_df: The dataframe being processed\n",
        "            df_cpt: The CPT reference dataframe\n",
        "            idx: The row index to process\n",
        "\n",
        "        Returns:\n",
        "            tuple: (updated_cpt, modified_cpt) - Processed CPT code lists\n",
        "        \"\"\"\n",
        "        # Get the original CPT codes, handling NaN values\n",
        "        cpt_codes = str(processed_df.loc[idx, \"CPT_codes\"]) if pd.notna(processed_df.loc[idx, \"CPT_codes\"]) else \"\"\n",
        "\n",
        "        # Skip processing if \"nan\" is the value (converted from NaN)\n",
        "        if cpt_codes == \"nan\":\n",
        "            cpt_codes = \"\"\n",
        "\n",
        "        # Debug: Print CPT codes for some rows to verify\n",
        "      #  if idx < 3 or idx % 100 == 0:\n",
        "       #     if cpt_codes:\n",
        "       #         print(f\"\\nRow {idx} - Original CPT codes: {cpt_codes}\")\n",
        "\n",
        "        # Split the CPT codes string into individual codes and clean whitespace\n",
        "        individual_codes = [code.strip() for code in cpt_codes.split(',') if code.strip()]\n",
        "\n",
        "        # Track rows with CPT codes\n",
        "        if individual_codes:\n",
        "            self.cpt_tracking[\"rows_with_cpt_codes\"] += 1\n",
        "\n",
        "        # Initialize lists to store updated and modified CPT codes\n",
        "        updated_cpt = []\n",
        "        modified_cpt = []\n",
        "\n",
        "        # Process each individual CPT code\n",
        "        for code in individual_codes:\n",
        "            self.cpt_tracking[\"total_codes_processed\"] += 1\n",
        "\n",
        "            # Debug: Print code being processed for the first few rows\n",
        "           # if idx < 3:\n",
        "            #    print(f\"  - Processing CPT code: {code}\")\n",
        "\n",
        "            # First, add the original code to updated_cpt (any custom transformations would go here)\n",
        "            updated_cpt.append(code)\n",
        "\n",
        "            try:\n",
        "                # Ensure type consistency by converting code to string and cleaning it\n",
        "                code_str = str(code).strip()\n",
        "\n",
        "                # Remove any commas, semicolons, or other delimiters that might affect matching\n",
        "                code_clean = code_str.replace(',', '').replace(';', '').replace('.', '').strip()\n",
        "\n",
        "                # Try both string and numeric matching to handle type differences\n",
        "                # First try exact string match with clean codes\n",
        "                matches = df_cpt[df_cpt['CPT_CODE_clean'] == code_clean]\n",
        "\n",
        "                # If no match, try converting to numeric if possible\n",
        "                if matches.empty and code_clean.isdigit():\n",
        "                    # Try numeric match if code is a number\n",
        "                    try:\n",
        "                        code_int = int(code_clean)\n",
        "                        matches = df_cpt[df_cpt['CPT_CODE_clean'].astype(float) == code_int]\n",
        "                  #      if idx < 3 and not matches.empty:\n",
        "                   #         print(f\"    ✓ Found match for {code} using numeric comparison\")\n",
        "                    except (ValueError, TypeError):\n",
        "                        # If conversion fails, continue with empty matches\n",
        "                        pass\n",
        "\n",
        "                if not matches.empty:\n",
        "                    self.cpt_tracking[\"codes_with_matches\"] += 1\n",
        "                    # If a match is found, get the Modified_CPT value\n",
        "                    modified_value = matches.iloc[0]['Modified_CPT']\n",
        "                    if pd.notna(modified_value):\n",
        "                        modified_cpt.append(str(modified_value))\n",
        "                     #   if idx < 3:\n",
        "                     #       print(f\"    ✓ Found match for {code}: {modified_value}\")\n",
        "                  #  else:\n",
        "                        # If Modified_CPT is NaN, don't include this code\n",
        "                      #  if idx < 3:\n",
        "                       #     print(f\"    ⚠️ Found match for {code} but Modified_CPT is NaN, excluding from modified codes\")\n",
        "                else:\n",
        "                    self.cpt_tracking[\"codes_without_matches\"] += 1\n",
        "                    # If no match is found, exclude this code from modified_cpt list\n",
        "                #    if idx < 3:\n",
        "                 #      print(f\"    ❌ No match found for {code}, excluding from modified codes\")\n",
        "            except Exception as e:\n",
        "                self.cpt_tracking[\"errors\"] += 1\n",
        "                self.debug_print(f\"Error processing CPT code {code} in row {idx}: {str(e)}\", \"ERROR\")\n",
        "                # If an error occurs, use the original code\n",
        "                modified_cpt.append(code)\n",
        "\n",
        "        return updated_cpt, modified_cpt\n",
        "\n",
        "    def determine_equipment(self, processed_df, idx):\n",
        "        \"\"\"Determine equipment used based on procedure descriptions.\n",
        "\n",
        "        Args:\n",
        "            processed_df: The dataframe being processed\n",
        "            idx: The row index to process\n",
        "\n",
        "        Returns:\n",
        "            list: Equipment identified in the procedure\n",
        "        \"\"\"\n",
        "        equipment = []\n",
        "\n",
        "        # Check for various equipment in the procedure descriptions\n",
        "        procedure_text = str(processed_df.loc[idx, \"all_written_procedures\"]).lower() if pd.notna(processed_df.loc[idx, \"all_written_procedures\"]) else \"\"\n",
        "\n",
        "        # Skip processing if \"nan\" is the value (converted from NaN)\n",
        "        if procedure_text == \"nan\":\n",
        "            procedure_text = \"\"\n",
        "\n",
        "        # Check for robotic procedures\n",
        "        if \"robotic\" in procedure_text:\n",
        "            equipment.append(\"Robotic: 20221\")\n",
        "\n",
        "        # Check for CO2 laser\n",
        "        if \"co2\" in procedure_text or \"carbon dioxide\" in procedure_text:\n",
        "            equipment.append(\"Laser-CO2: 20215\")\n",
        "\n",
        "        # Check for sialendoscopy\n",
        "        if \"sialendoscopy\" in procedure_text:\n",
        "            equipment.append(\"Sialendoscopy: 20885\")\n",
        "\n",
        "        # Check for KTP laser\n",
        "        if \"ktp\" in procedure_text:\n",
        "            equipment.append(\"Laser-KTP: 20216\")\n",
        "\n",
        "        return equipment\n",
        "\n",
        "    def determine_age_category(self, age_days):\n",
        "        \"\"\"Determine patient age category based on age in days.\n",
        "\n",
        "        Args:\n",
        "            age_days: Patient age in days\n",
        "\n",
        "        Returns:\n",
        "            str: Age category string\n",
        "        \"\"\"\n",
        "        if pd.notna(age_days):\n",
        "            if age_days < 28:\n",
        "                return \"Neonate (<28 days): 114\"\n",
        "            elif age_days >= 28 and age_days < (3 * 365):\n",
        "                return \"Infant/Toddler(>=28-<3yr): 113\"\n",
        "            elif age_days >= (3 * 365) and age_days < (13 * 365):\n",
        "                return \"Child(>;= 3 - < 13 yrs): 112\"\n",
        "            elif age_days >= (13 * 365) and age_days < (18 * 365):\n",
        "                return \"Adolescent(>= 13 -<18 yr): 110\"\n",
        "            else:\n",
        "                return \"Adult (>= 18 yrs): 111\"\n",
        "        else:\n",
        "            return \"Unknown\"\n",
        "\n",
        "    def process_consultant_data(self, processed_df, df_consultants):\n",
        "        \"\"\"Process consultant data to create corrected_consultant column.\"\"\"\n",
        "        print(\"\\n🔄 Processing consultant data...\")\n",
        "\n",
        "        # Create case-insensitive mapping of consultant names to their indices\n",
        "        consultant_dict = {name.upper().strip(): index for name, index in\n",
        "                        zip(df_consultants.iloc[:, 0], df_consultants.iloc[:, 1])}\n",
        "\n",
        "        # Log the consultant dictionary (first few entries)\n",
        "       # print(f\"\\n📊 Consultant mapping dictionary (first 5 entries):\")\n",
        "       # for i, (name, index) in enumerate(list(consultant_dict.items())[:5]):\n",
        "        #    print(f\"  - {name} -> {index}\")\n",
        "\n",
        "        # Initialize new column\n",
        "        processed_df['corrected_consultant'] = \"\"\n",
        "\n",
        "        # Process each row for consultant correction\n",
        "        for idx in tqdm(range(len(processed_df)), desc=\"Processing consultant data\"):\n",
        "            try:\n",
        "                # Get the primary consultant name\n",
        "                primary_consultant = str(processed_df.loc[idx, \"Primary_surgeon\"]).strip() if pd.notna(processed_df.loc[idx, \"Primary_surgeon\"]) else \"\"\n",
        "\n",
        "                # Skip processing if \"nan\" is the value\n",
        "                if primary_consultant.lower() == \"nan\":\n",
        "                    primary_consultant = \"\"\n",
        "\n",
        "                # Extract last name more intelligently, handling compound last names\n",
        "                found_match = False\n",
        "\n",
        "                # Try checking if the full primary consultant last name is in the list\n",
        "                if primary_consultant:\n",
        "                    # This handles cases where the full last name is stored in consultant_dict\n",
        "                    # For example, \"Van Abel\" or \"De La Cruz\" would be matched as complete names\n",
        "                    primary_last_name = primary_consultant.upper()\n",
        "                    if primary_last_name in consultant_dict:\n",
        "                        processed_df.loc[idx, \"corrected_consultant\"] = consultant_dict[primary_last_name]\n",
        "                        found_match = True\n",
        "                    else:\n",
        "                        # Try to match with just the last part - this might work for simpler names\n",
        "                        last_word = primary_consultant.split()[-1].upper() if primary_consultant else \"\"\n",
        "                        if last_word in consultant_dict:\n",
        "                            processed_df.loc[idx, \"corrected_consultant\"] = consultant_dict[last_word]\n",
        "                            found_match = True\n",
        "\n",
        "                # If no match found in primary surgeon, check the list of all providers\n",
        "                if not found_match:\n",
        "                    all_providers = str(processed_df.loc[idx, \"All_providers\"]) if pd.notna(processed_df.loc[idx, \"All_providers\"]) else \"\"\n",
        "\n",
        "                    # Skip processing if \"nan\" is the value\n",
        "                    if all_providers.lower() == \"nan\":\n",
        "                        all_providers = \"\"\n",
        "\n",
        "                    # Split by semicolon and check each name\n",
        "                    if all_providers:\n",
        "                        for provider in all_providers.split(';'):\n",
        "                            provider = provider.strip()\n",
        "\n",
        "                            # Try matching the full provider name first\n",
        "                            if provider.upper() in consultant_dict:\n",
        "                                processed_df.loc[idx, \"corrected_consultant\"] = consultant_dict[provider.upper()]\n",
        "                                found_match = True\n",
        "                                break\n",
        "\n",
        "                            # If full name doesn't match, try just the last part\n",
        "                            provider_parts = provider.split()\n",
        "                            if provider_parts:\n",
        "                                provider_last_name = provider_parts[-1].upper()\n",
        "                                if provider_last_name in consultant_dict:\n",
        "                                    processed_df.loc[idx, \"corrected_consultant\"] = consultant_dict[provider_last_name]\n",
        "                                    found_match = True\n",
        "                                    break\n",
        "\n",
        "                    # If no match found in either primary or all providers, use default\n",
        "                    if not found_match:\n",
        "                        processed_df.loc[idx, \"corrected_consultant\"] = \"Program, Other: 280213\"\n",
        "\n",
        "                # Debug: Print consultant processing for some rows\n",
        "              #  if idx < 3 or idx % 100 == 0:\n",
        "                #    print(f\"\\nRow {idx} - Primary consultant: {primary_consultant}\")\n",
        "                #    print(f\"  → Corrected consultant: {processed_df.loc[idx, 'corrected_consultant']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                self.debug_print(f\"Error processing consultant in row {idx}: {str(e)}\", \"ERROR\")\n",
        "                # Use default if error occurs\n",
        "                processed_df.loc[idx, \"corrected_consultant\"] = \"Program, Other: 280213\"\n",
        "\n",
        "        return processed_df\n",
        "\n",
        "    def process_key_indicators(self, processed_df, df_cpt):\n",
        "        \"\"\"Process CPT codes to extract key indicators.\n",
        "\n",
        "        Args:\n",
        "            processed_df: The dataframe being processed\n",
        "            df_cpt: The CPT reference dataframe\n",
        "\n",
        "        Returns:\n",
        "            DataFrame: Updated dataframe with key_indicators column\n",
        "        \"\"\"\n",
        "        print(\"\\n🔄 Processing key indicators data...\")\n",
        "\n",
        "        # Check if df_cpt has the key indicator column\n",
        "        key_indicator_col = None\n",
        "        potential_key_cols = [col for col in df_cpt.columns if 'indicator_type_abbr' in col.lower()]\n",
        "        if potential_key_cols:\n",
        "            key_indicator_col = potential_key_cols[0]\n",
        "            print(f\"Using '{key_indicator_col}' as the Key Indicator column\")\n",
        "        else:\n",
        "            self.debug_print(\"No Key Indicator column found in df_cpt. Creating empty key indicators column.\", \"WARNING\")\n",
        "\n",
        "        # Initialize key indicators column\n",
        "        processed_df['key_indicators'] = \"\"\n",
        "\n",
        "        # Process each row to extract key indicators from CPT codes\n",
        "        for idx in tqdm(range(len(processed_df)), desc=\"Processing key indicators\"):\n",
        "            try:\n",
        "                # Get the modified CPT codes\n",
        "                cpt_codes = str(processed_df.loc[idx, \"modified CPT codes\"]) if pd.notna(processed_df.loc[idx, \"modified CPT codes\"]) else \"\"\n",
        "\n",
        "                # Skip processing if \"nan\" is the value or empty\n",
        "                if cpt_codes.lower() == \"nan\" or not cpt_codes:\n",
        "                    continue\n",
        "\n",
        "                # Split the CPT codes string into individual codes and clean whitespace\n",
        "                individual_codes = [code.strip() for code in cpt_codes.split(',') if code.strip()]\n",
        "\n",
        "                # Initialize list to store key indicators\n",
        "                key_indicators = []\n",
        "\n",
        "                # Process each CPT code to find its key indicator\n",
        "                for code in individual_codes:\n",
        "                    # Clean the code for matching\n",
        "                    code_clean = str(code).replace(',', '').replace(';', '').replace('.', '').strip()\n",
        "\n",
        "                    # Skip if no key indicator column was found\n",
        "                    if not key_indicator_col:\n",
        "                        continue\n",
        "\n",
        "                    # Find matches in the CPT dataframe\n",
        "                    matches = df_cpt[df_cpt['CPT_CODE_clean'] == code_clean]\n",
        "\n",
        "                    # If matches found, get the key indicator\n",
        "                    if not matches.empty:\n",
        "                        key_indicator = matches.iloc[0][key_indicator_col]\n",
        "                        if pd.notna(key_indicator) and str(key_indicator).strip():\n",
        "                            key_indicators.append(str(key_indicator).strip())\n",
        "\n",
        "                # Remove duplicates and join with semicolons\n",
        "                unique_indicators = list(set(key_indicators))\n",
        "                processed_df.loc[idx, \"key_indicators\"] = '; '.join(unique_indicators) if unique_indicators else \"\"\n",
        "\n",
        "                # Debug: Print key indicators for some rows\n",
        "              #  if idx < 3 or idx % 100 == 0:\n",
        "                   # if individual_codes:\n",
        "                   #     print(f\"\\nRow {idx} - CPT codes: {cpt_codes}\")\n",
        "                   #     print(f\"  → Key indicators: {processed_df.loc[idx, 'key_indicators']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                self.debug_print(f\"Error processing key indicators in row {idx}: {str(e)}\", \"ERROR\")\n",
        "\n",
        "        return processed_df\n",
        "\n",
        "    def process_data(self, combined_df, df_cpt, df_consultants):\n",
        "        \"\"\"Process the resident case data with all enrichments.\n",
        "\n",
        "        Args:\n",
        "            combined_df: The input dataframe with resident case data\n",
        "            df_cpt: The CPT reference dataframe\n",
        "            df_consultants: The consultant reference dataframe\n",
        "\n",
        "        Returns:\n",
        "            DataFrame: Processed and enriched dataframe\n",
        "        \"\"\"\n",
        "        print(\"\\n🔄 Processing surgical data...\")\n",
        "        self.update_progress(80, \"Processing resident case data...\")\n",
        "\n",
        "        # Make a copy of the dataframe to work with\n",
        "        try:\n",
        "            processed_df = combined_df.copy()\n",
        "            # Debug: Show combined_df structure\n",
        "          #  print(\"\\n📊 Combined DataFrame columns:\", combined_df.columns.tolist())\n",
        "          #  print(f\"📊 Combined DataFrame has {len(combined_df)} rows\")\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error copying dataframe: {str(e)}\", \"ERROR\")\n",
        "            raise\n",
        "\n",
        "        # Initialize new columns for CPT code tracking\n",
        "        processed_df['Updated_CPT_codes'] = \"\"\n",
        "        processed_df['modified CPT codes'] = \"\"\n",
        "\n",
        "        # Prepare the CPT dataframe for matching\n",
        "        df_cpt = self.prepare_cpt_dataframe(df_cpt)\n",
        "\n",
        "        # Process data with progress bar\n",
        "        for idx in tqdm(range(len(processed_df)), desc=\"Processing patient data\"):\n",
        "            try:\n",
        "                # 1. Calculate patient age category based on days\n",
        "                age_days = processed_df.loc[idx, \"Pt_Age_In_Days\"]\n",
        "                processed_df.loc[idx, \"Patient_Age_Category\"] = self.determine_age_category(age_days)\n",
        "\n",
        "                # 2. Update CPT codes based on rules\n",
        "                updated_cpt, modified_cpt = self.process_cpt_codes(processed_df, df_cpt, idx)\n",
        "\n",
        "                # Join the processed codes and update the dataframe\n",
        "                processed_df.loc[idx, \"Updated_CPT_codes\"] = ', '.join(updated_cpt) if updated_cpt else \"\"\n",
        "                processed_df.loc[idx, \"modified CPT codes\"] = ', '.join(modified_cpt) if modified_cpt else \"\"\n",
        "\n",
        "                # Debug: Print updated values for some rows\n",
        "                if idx < 3 and (updated_cpt or modified_cpt):\n",
        "                    print(f\"  → Updated CPT codes: {processed_df.loc[idx, 'Updated_CPT_codes']}\")\n",
        "                    print(f\"  → Modified CPT codes: {processed_df.loc[idx, 'modified CPT codes']}\")\n",
        "\n",
        "                # 3. Determine equipment used\n",
        "                equipment = self.determine_equipment(processed_df, idx)\n",
        "\n",
        "                # Set equipment value, with \"N/A: 20214\" for empty values\n",
        "                processed_df.loc[idx, \"equipment\"] = '; '.join(equipment) if equipment else \"N/A: 20214\"\n",
        "\n",
        "            except Exception as e:\n",
        "                self.debug_print(f\"Error processing row {idx}: {str(e)}\", \"ERROR\")\n",
        "                # Continue with next row instead of failing completely\n",
        "                continue\n",
        "\n",
        "        # Process consultant data to create corrected_consultant column\n",
        "        self.update_progress(85, \"Processing consultant data...\")\n",
        "        processed_df = self.process_consultant_data(processed_df, df_consultants)\n",
        "\n",
        "        # Process key indicators\n",
        "        self.update_progress(90, \"Processing key indicators...\")\n",
        "        processed_df = self.process_key_indicators(processed_df, df_cpt)\n",
        "\n",
        "        # Display CPT code processing statistics\n",
        "        print(\"\\n📊 CPT Code Processing Statistics:\")\n",
        "        print(f\"Total rows with CPT codes: {self.cpt_tracking['rows_with_cpt_codes']} out of {len(processed_df)}\")\n",
        "        print(f\"Total individual CPT codes processed: {self.cpt_tracking['total_codes_processed']}\")\n",
        "        print(f\"CPT codes with matches in reference data: {self.cpt_tracking['codes_with_matches']}\")\n",
        "        print(f\"CPT codes without matches: {self.cpt_tracking['codes_without_matches']}\")\n",
        "        print(f\"Errors during processing: {self.cpt_tracking['errors']}\")\n",
        "\n",
        "        # Verify that our new columns were properly populated\n",
        "        print(\"\\n✅ Verification of CPT code processing:\")\n",
        "        non_empty_updated = processed_df['Updated_CPT_codes'].str.strip().str.len() > 0\n",
        "        non_empty_modified = processed_df['modified CPT codes'].str.strip().str.len() > 0\n",
        "        print(f\"Rows with non-empty Updated_CPT_codes: {non_empty_updated.sum()} out of {len(processed_df)}\")\n",
        "        print(f\"Rows with non-empty modified CPT codes: {non_empty_modified.sum()} out of {len(processed_df)}\")\n",
        "\n",
        "        # Sample data with non-empty modified CPT codes\n",
        "        #print(\"\\n📊 Sample rows with modified CPT codes:\")\n",
        "        #sample_rows = processed_df[non_empty_modified].head(5)\n",
        "        #sample_display = pd.DataFrame({\n",
        "        #    'Original CPT': sample_rows['CPT_codes'],\n",
        "        #    'Modified CPT': sample_rows['modified CPT codes']\n",
        "       # })\n",
        "        #display(sample_display)\n",
        "\n",
        "        return processed_df\n",
        "\n",
        "    def create_summary_dataframe(self, processed_df):\n",
        "        \"\"\"Create a summary dataframe with selected columns.\n",
        "\n",
        "        Args:\n",
        "            processed_df: The processed dataframe\n",
        "\n",
        "        Returns:\n",
        "            DataFrame: Summary dataframe\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.update_progress(92, \"Creating summary dataframe...\")\n",
        "\n",
        "            # Create a new DataFrame with selected and transformed columns\n",
        "            df_summary = pd.DataFrame({\n",
        "                \"Resident Name\": processed_df[\"Resident_first_name\"].str.strip() + \" \" + processed_df[\"Resident_last_name\"].str.strip(),\n",
        "                \"Case_ID\": processed_df[\"SURGICAL_CASE_FPK\"],\n",
        "                \"Case_Date\": pd.to_datetime(processed_df[\"Surgery_date\"]).dt.date,\n",
        "                \"Special_equipment\": processed_df[\"equipment\"],\n",
        "                \"Role\": processed_df[\"Role\"],\n",
        "                \"Site\": \"Mayo Clinic (Rochester): 12793\",\n",
        "                \"Attending\": processed_df[\"corrected_consultant\"],  # New column\n",
        "                \"CPT codes\": processed_df[\"modified CPT codes\"],\n",
        "                \"Patient_age\": processed_df[\"Patient_Age_Category\"],\n",
        "                \"Post-op procedure description\": processed_df[\"written_procedures_summarized\"],\n",
        "                \"Procedure name\": processed_df[\"Procedure_descriptions\"],\n",
        "                \"Pre-op preocedure info\": processed_df[\"all_written_procedures\"],\n",
        "                \"Key_indicators\": processed_df[\"key_indicators\"],  # New column\n",
        "                \"All surgeons\": processed_df[\"All_providers\"],\n",
        "                \"Pt age (days)\": processed_df[\"Pt_Age_In_Days\"],\n",
        "                \"Pt MRN\": processed_df[\"MRN\"],\n",
        "                \"Resident Email\": processed_df[\"Prov_email\"],\n",
        "                \"Primary_surgeon_listed\": processed_df[\"Primary_surgeon\"],\n",
        "                \"Original CPT codes\": processed_df[\"CPT_codes\"],\n",
        "                \"Updated_CPT codes\": processed_df[\"Updated_CPT_codes\"],\n",
        "            })\n",
        "\n",
        "            # First, count the total rows before any filtering\n",
        "            original_row_count = len(df_summary)\n",
        "\n",
        "            # Remove rows containing \"EVACUATION HEMATOMA\" in Post-op procedure description\n",
        "            hematoma_mask = ~df_summary[\"Post-op procedure description\"].str.contains(\"EVACUATION HEMATOMA\", case=False, na=False)\n",
        "            df_summary = df_summary[hematoma_mask]\n",
        "\n",
        "            # Count rows after hematoma filtering\n",
        "            after_hematoma_count = len(df_summary)\n",
        "            hematoma_rows_removed = original_row_count - after_hematoma_count\n",
        "            print(f\"\\n✅ Removed {hematoma_rows_removed} rows containing 'EVACUATION HEMATOMA'\")\n",
        "\n",
        "            # Remove rows where \"CPT codes\" is blank or empty\n",
        "            df_summary = df_summary[df_summary[\"CPT codes\"].notna() &\n",
        "                                (df_summary[\"CPT codes\"].str.strip() != \"\")]\n",
        "\n",
        "            # Calculate final counts\n",
        "            final_row_count = len(df_summary)\n",
        "            empty_cpt_rows_removed = after_hematoma_count - final_row_count\n",
        "            total_removed_rows = original_row_count - final_row_count\n",
        "\n",
        "            print(f\"✅ Removed {empty_cpt_rows_removed} rows with empty CPT codes\")\n",
        "            print(f\"✅ Total removed: {total_removed_rows} rows ({hematoma_rows_removed} hematoma + {empty_cpt_rows_removed} empty CPT)\")\n",
        "            print(f\"✅ Final dataset contains {final_row_count} rows out of original {original_row_count}\")\n",
        "\n",
        "            # Preview the summarized data\n",
        "            df_summary = df_summary.sort_values(by=[\"Resident Name\", \"Case_Date\"]).reset_index(drop=True)\n",
        "            display(Markdown(\"### 🩺 Condensed Surgical Case Log\"))\n",
        "            display(df_summary.head(10))\n",
        "\n",
        "            return df_summary\n",
        "\n",
        "        except Exception as e:\n",
        "            self.debug_print(f\"Error creating summary dataframe: {str(e)}\", \"ERROR\")\n",
        "            # Print the error traceback for debugging\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "\n",
        "# Initialize the interactive UI\n",
        "def initialize_ui(dict_residents):\n",
        "    \"\"\"Initialize the interactive UI with widgets.\n",
        "\n",
        "    Args:\n",
        "        dict_residents: List of resident dictionaries\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing all UI widgets\n",
        "    \"\"\"\n",
        "    # Display custom CSS for better styling\n",
        "    display(HTML(\"\"\"\n",
        "    <style>\n",
        "        .widget-label {\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            font-weight: 600 !important;\n",
        "            color: #2c3e50 !important;\n",
        "        }\n",
        "        .widget-select-multiple {\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 13px !important;\n",
        "        }\n",
        "        .widget-text {\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 13px !important;\n",
        "        }\n",
        "        .widget-checkbox {\n",
        "            font-size: 14px !important;\n",
        "        }\n",
        "        .widget-button {\n",
        "            font-family: 'Arial', sans-serif !important;\n",
        "            font-size: 14px !important;\n",
        "            font-weight: 600 !important;\n",
        "        }\n",
        "        .jupyter-widgets {\n",
        "            margin: 5px 0 !important;\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\"))\n",
        "\n",
        "    # Date picker widgets with better layout\n",
        "    today = datetime.now()\n",
        "    start_date_widget = widgets.DatePicker(\n",
        "        description='Start Date:',\n",
        "        value=datetime(2020, 1, 1).date(),  # January 1, 2020\n",
        "        disabled=False,\n",
        "        style={'description_width': '120px'},\n",
        "    )\n",
        "\n",
        "    end_date_widget = widgets.DatePicker(\n",
        "        description='End Date:',\n",
        "        value=today.date(),\n",
        "        disabled=False,\n",
        "        style={'description_width': '120px'},\n",
        "    )\n",
        "\n",
        "    # Create a horizontal box for date widgets\n",
        "    date_box = widgets.HBox([start_date_widget, end_date_widget],\n",
        "                            layout=widgets.Layout(margin='10px 0'))\n",
        "\n",
        "    # Create multi-select widget for residents with double width\n",
        "    valid_residents = [r for r in dict_residents if r[\"First name\"] != \"None\" and r[\"Email\"] != \"None\"]\n",
        "    resident_display_names = [f\"{r['First name']} {r['Last name']} ({r['Email']})\" for r in valid_residents]\n",
        "\n",
        "    resident_select = widgets.SelectMultiple(\n",
        "        options=list(zip(resident_display_names, range(len(valid_residents)))),\n",
        "        value=[],\n",
        "        description='Residents:',\n",
        "        rows=10,\n",
        "        style={'description_width': '120px'},\n",
        "        layout=widgets.Layout(width='600px')  # Double the default width\n",
        "    )\n",
        "\n",
        "    # Additional emails widget with improved layout\n",
        "    additional_emails_widget = widgets.Textarea(\n",
        "        value='',\n",
        "        placeholder='Enter additional emails, separated by commas',\n",
        "        description='Additional Emails:',\n",
        "        style={'description_width': '120px'},\n",
        "        layout=widgets.Layout(width='600px', height='60px')\n",
        "    )\n",
        "\n",
        "    # Add checkbox for Select All Residents\n",
        "    select_all_checkbox = widgets.Checkbox(\n",
        "        value=False,\n",
        "        description='Select All Residents',\n",
        "        disabled=False,\n",
        "        indent=False,\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    # Add checkboxes for including additional data\n",
        "    include_op_notes_widget = widgets.Checkbox(\n",
        "        value=False,\n",
        "        description='Include op notes',\n",
        "        disabled=False,\n",
        "        indent=False,\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    include_path_reports_widget = widgets.Checkbox(\n",
        "        value=False,\n",
        "        description='Include Pathology Reports',\n",
        "        disabled=False,\n",
        "        indent=False,\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    # Create a horizontal box for checkboxes\n",
        "    checkbox_box = widgets.HBox([\n",
        "        select_all_checkbox,\n",
        "        include_op_notes_widget,\n",
        "        include_path_reports_widget\n",
        "    ], layout=widgets.Layout(margin='10px 0', justify_content='flex-start'))\n",
        "\n",
        "    # Create button with improved styling\n",
        "    execute_button = widgets.Button(\n",
        "        description='Execute Query',\n",
        "        disabled=False,\n",
        "        button_style='primary',\n",
        "        tooltip='Click to execute the query',\n",
        "        icon='check',\n",
        "        layout=widgets.Layout(width='200px', margin='10px 0')\n",
        "    )\n",
        "\n",
        "    # Progress bar widget\n",
        "    progress_bar = widgets.IntProgress(\n",
        "        value=0,\n",
        "        min=0,\n",
        "        max=100,\n",
        "        description='Progress:',\n",
        "        bar_style='info',  # 'success', 'info', 'warning', 'danger' or ''\n",
        "        style={'bar_color': '#00cc88', 'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='600px', margin='10px 0')\n",
        "    )\n",
        "\n",
        "    # Status label widget\n",
        "    status_label = widgets.Label(value=\"Ready to execute query\")\n",
        "\n",
        "    # Output widget\n",
        "    output_widget = widgets.Output()\n",
        "\n",
        "    # Create a vertical box for progress bar and status\n",
        "    progress_box = widgets.VBox([progress_bar, status_label])\n",
        "\n",
        "    # Function to handle select all checkbox\n",
        "    def on_select_all_change(change):\n",
        "        if change['new']:\n",
        "            resident_select.value = tuple(range(len(valid_residents)))\n",
        "        else:\n",
        "            resident_select.value = []\n",
        "\n",
        "    select_all_checkbox.observe(on_select_all_change, names='value')\n",
        "\n",
        "    # Create a well-organized layout\n",
        "    display(HTML(\"<h3 style='font-family: Arial, sans-serif; color: #2c3e50;'>Resident Case Query Tool</h3>\"))\n",
        "    display(date_box)\n",
        "    display(resident_select)\n",
        "    display(additional_emails_widget)\n",
        "    display(checkbox_box)\n",
        "    display(execute_button)\n",
        "    display(progress_box)\n",
        "    display(output_widget)\n",
        "\n",
        "    # Return all widgets in a dictionary\n",
        "    return {\n",
        "        'start_date': start_date_widget,\n",
        "        'end_date': end_date_widget,\n",
        "        'resident_select': resident_select,\n",
        "        'additional_emails': additional_emails_widget,\n",
        "        'select_all': select_all_checkbox,\n",
        "        'include_op_notes': include_op_notes_widget,\n",
        "        'include_path_reports': include_path_reports_widget,\n",
        "        'execute_button': execute_button,\n",
        "        'progress_bar': progress_bar,\n",
        "        'status_label': status_label,\n",
        "        'output': output_widget,\n",
        "        'valid_residents': valid_residents\n",
        "    }\n",
        "\n",
        "\n",
        "# Function to update progress bar\n",
        "def update_progress(ui, value, status_text=\"\"):\n",
        "    \"\"\"Update progress bar and status label.\n",
        "\n",
        "    Args:\n",
        "        ui: Dictionary of UI widgets\n",
        "        value: Progress value (0-100)\n",
        "        status_text: Status message\n",
        "    \"\"\"\n",
        "    ui['progress_bar'].value = value\n",
        "    if status_text:\n",
        "        ui['status_label'].value = status_text\n",
        "\n",
        "\n",
        "# Function to handle button click\n",
        "def setup_execute_handler(ui, dict_residents):\n",
        "    \"\"\"Set up the handler for the execute button.\n",
        "\n",
        "    Args:\n",
        "        ui: Dictionary of UI widgets\n",
        "        dict_residents: List of resident dictionaries\n",
        "    \"\"\"\n",
        "\n",
        "    def on_execute_button_clicked(b):\n",
        "        with ui['output']:\n",
        "            ui['output'].clear_output()\n",
        "\n",
        "            # Reset progress bar\n",
        "            update_progress(ui, 0, \"Starting query execution...\")\n",
        "\n",
        "            # Get selected residents' emails\n",
        "            selected_indices = list(ui['resident_select'].value)\n",
        "            selected_emails = [ui['valid_residents'][i][\"Email\"] for i in selected_indices]\n",
        "\n",
        "            # Add additional emails if any\n",
        "            additional_emails = [e.strip() for e in ui['additional_emails'].value.split(',') if e.strip()]\n",
        "            all_emails = selected_emails + additional_emails\n",
        "\n",
        "            if not all_emails:\n",
        "                print(\"❌ Please select at least one resident or add an email address.\")\n",
        "                return\n",
        "\n",
        "            # Get dates\n",
        "            start = ui['start_date'].value.strftime('%Y-%m-%d')\n",
        "            end = ui['end_date'].value.strftime('%Y-%m-%d')\n",
        "\n",
        "            # Get checkbox values\n",
        "            include_op_notes = ui['include_op_notes'].value\n",
        "            include_path_reports = ui['include_path_reports'].value\n",
        "\n",
        "            print(f\"🔍 Searching for cases from {start} to {end}\")\n",
        "            print(f\"📧 Selected emails: {', '.join(all_emails)}\")\n",
        "            print(f\"📄 Include Operation Notes: {'Yes' if include_op_notes else 'No'}\")\n",
        "            print(f\"🔬 Include Pathology Reports: {'Yes' if include_path_reports else 'No'}\")\n",
        "\n",
        "            # Initialize the DataLoader and ResidentCaseProcessor\n",
        "            try:\n",
        "                loader = DataLoader()\n",
        "                processor = ResidentCaseProcessor()\n",
        "\n",
        "                # Set progress callback functions\n",
        "                loader.set_progress_callback(lambda value, text: update_progress(ui, value, text))\n",
        "                processor.set_progress_callback(lambda value, text: update_progress(ui, value, text))\n",
        "\n",
        "                # Create the combined dataframe\n",
        "                update_progress(ui, 10, \"Initializing connections...\")\n",
        "                combined_df, df_cpt, df_consultants = loader.create_combined_dataframe(\n",
        "                    start,\n",
        "                    end,\n",
        "                    all_emails,\n",
        "                    include_op_notes,\n",
        "                    include_path_reports\n",
        "                )\n",
        "\n",
        "                # Process the data\n",
        "                processed_df = processor.process_data(combined_df, df_cpt, df_consultants)\n",
        "\n",
        "                # Create the summary dataframe\n",
        "                df_summary = processor.create_summary_dataframe(processed_df)\n",
        "\n",
        "                # Save the results\n",
        "                today_date = datetime.now().strftime('%Y-%m-%d')\n",
        "                summary_filename = f\"Condensed_resident_case_data_{today_date}.xlsx\"\n",
        "                local_path = loader.save_dataframe(df_summary, summary_filename, \"Resident Cases\")\n",
        "\n",
        "                # Display download link\n",
        "                display(FileLink(local_path))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error: {str(e)}\")\n",
        "                update_progress(ui, 0, \"Error occurred during processing\")\n",
        "                traceback.print_exc()\n",
        "                return\n",
        "\n",
        "    # Connect button to function\n",
        "    ui['execute_button'].on_click(on_execute_button_clicked)\n",
        "\n",
        "\n",
        "# Main function to run the application\n",
        "def run_app(dict_residents):\n",
        "    \"\"\"Run the complete application with UI.\n",
        "\n",
        "    Args:\n",
        "        dict_residents: List of resident dictionaries\n",
        "    \"\"\"\n",
        "    # Initialize UI\n",
        "    ui = initialize_ui(dict_residents)\n",
        "\n",
        "    # Setup execute handler\n",
        "    setup_execute_handler(ui, dict_residents)\n",
        "\n",
        "    print(\"✅ Application initialized. Use the UI above to query and process resident case data.\")\n",
        "\n",
        "# Execute the resident data update process\n",
        "if __name__ == \"__main__\" or 'get_ipython' in globals():\n",
        "    try:\n",
        "        # Initialize DataLoader\n",
        "        loader = DataLoader()\n",
        "\n",
        "        # Combine and save resident data\n",
        "        print(\"📊 Starting resident data update process...\")\n",
        "        combined_residents = loader.combine_and_save_resident_data()\n",
        "        print(f\"✅ Successfully updated resident data with {len(combined_residents)} entries\")\n",
        "\n",
        "        # Now that we have the combined data, run the application\n",
        "        run_app(combined_residents)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error updating resident data: {str(e)}\")\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "collapsed_sections": [
        "2XGgtY_vugwT",
        "97AlcLEkzJD_"
      ],
      "name": "ENT_provider_cases_Daily_run_04.27.25",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03daf25606f6432894c47de160c9b112": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "041c9ae2c8874e6681b6f612a0119c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a019cb5722543c79187adbbd6b91730": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e53df8bac984686a3b4864491071877": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b63d6f9322b48efbbb4b139cfceffce",
              "IPY_MODEL_e476d04627824a68bc5a8d58644afe1e",
              "IPY_MODEL_e0c554cc7c484878b12e057f22aca06f"
            ],
            "layout": "IPY_MODEL_6badc4aec5234c7fa8a75e7fdf28ab84"
          }
        },
        "20be15c97e52429a9caf8107708e0fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebaa7d9307dc47069dd30fc65b4c572c",
            "placeholder": "​",
            "style": "IPY_MODEL_4347ab14912a41edaab6375092d4c85e",
            "value": "Processing patient data: 100%"
          }
        },
        "23cab81540074a568c3e454fed7f16e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a607d53b44847c88904a3fa5d7d4e77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349607819b2e49da92a4ffbb28e59107": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39fd65308a4f4972ab768297e968e25e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4347ab14912a41edaab6375092d4c85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c83945c96d741db9672de64e1354158": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d61a63e3ed44469e22c6267bb9fb27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591bede3e78e4307a61a2125c3716b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c82432810fd4eceb2c493e6691b83db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60776d7ee20648e5885047ae6a4251d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbdf7ec72d4d4349a6a0774cdfbb4eeb",
              "IPY_MODEL_f529490c3dfa4aedb3f2deb454c93773",
              "IPY_MODEL_b267eeaaf94741eebeef16542d92a835"
            ],
            "layout": "IPY_MODEL_4c83945c96d741db9672de64e1354158"
          }
        },
        "61ee0e70c00b45a993eeb4c8972871c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ad64f4efb3141988223fdb0de1dd9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa7fb80197394df8af6100d9dfa81570",
            "placeholder": "​",
            "style": "IPY_MODEL_03daf25606f6432894c47de160c9b112",
            "value": " 21979/21979 [01:02&lt;00:00, 330.09it/s]"
          }
        },
        "6badc4aec5234c7fa8a75e7fdf28ab84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73157ef6c0c64950a4958ede22ab246d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a46e6d10849476199b6b4f0f954d3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b63d6f9322b48efbbb4b139cfceffce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23cab81540074a568c3e454fed7f16e3",
            "placeholder": "​",
            "style": "IPY_MODEL_5c82432810fd4eceb2c493e6691b83db",
            "value": "Processing patient data: 100%"
          }
        },
        "9ebddd718a77411e81fd6650f0896b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20be15c97e52429a9caf8107708e0fa1",
              "IPY_MODEL_d367a7f10d2f496cb7c895fa198940f2",
              "IPY_MODEL_6ad64f4efb3141988223fdb0de1dd9c0"
            ],
            "layout": "IPY_MODEL_50d61a63e3ed44469e22c6267bb9fb27"
          }
        },
        "aa7fb80197394df8af6100d9dfa81570": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b267eeaaf94741eebeef16542d92a835": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a46e6d10849476199b6b4f0f954d3b5",
            "placeholder": "​",
            "style": "IPY_MODEL_61ee0e70c00b45a993eeb4c8972871c4",
            "value": " 95/95 [00:00&lt;00:00, 909.09it/s]"
          }
        },
        "c0badda96abd4a4db64b611c85e3a3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d367a7f10d2f496cb7c895fa198940f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73157ef6c0c64950a4958ede22ab246d",
            "max": 21979,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0badda96abd4a4db64b611c85e3a3a6",
            "value": 21979
          }
        },
        "d582a7332cd74b95a6a0c277a12bd1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd698ced3cd64666829acc3f0b3892b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0c554cc7c484878b12e057f22aca06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a019cb5722543c79187adbbd6b91730",
            "placeholder": "​",
            "style": "IPY_MODEL_dd698ced3cd64666829acc3f0b3892b3",
            "value": " 21979/21979 [01:01&lt;00:00, 346.83it/s]"
          }
        },
        "e476d04627824a68bc5a8d58644afe1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a607d53b44847c88904a3fa5d7d4e77",
            "max": 21979,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_349607819b2e49da92a4ffbb28e59107",
            "value": 21979
          }
        },
        "ebaa7d9307dc47069dd30fc65b4c572c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f529490c3dfa4aedb3f2deb454c93773": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041c9ae2c8874e6681b6f612a0119c6d",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_591bede3e78e4307a61a2125c3716b9c",
            "value": 95
          }
        },
        "fbdf7ec72d4d4349a6a0774cdfbb4eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39fd65308a4f4972ab768297e968e25e",
            "placeholder": "​",
            "style": "IPY_MODEL_d582a7332cd74b95a6a0c277a12bd1a9",
            "value": "Processing patient data: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
